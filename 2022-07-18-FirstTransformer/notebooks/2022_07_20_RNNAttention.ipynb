{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/text/tutorials/nmt_with_attention"
      ],
      "metadata": {
        "id": "j77hUjNXm5ib"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qEH2hbKAK5D",
        "outputId": "58f98cb1-161d-4a0a-96a1-c0e53c196f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: icecream in /usr/local/lib/python3.7/dist-packages (2.1.2)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.7/dist-packages (8.13.0)\n",
            "Requirement already satisfied: executing>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.8.3)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.4.5)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "pip install icecream more_itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuKVH3YBBd6C",
        "outputId": "fdc451e1-0050-4d82-a82c-fc05c2ae40df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# only needed for colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xzulqDrkBhLc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/SYMBA/2022-07-20-RNNAttention')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5c0dUUGBr5W",
        "outputId": "a78f6b74-5f32-4fed-d3a6-a144e00342d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['notebooks',\n",
              " 'README.md',\n",
              " 'env.yml',\n",
              " 'dev',\n",
              " 'source',\n",
              " 'models',\n",
              " '.ipynb_checkpoints']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9A9Y1io1AKa6"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from icecream import ic \n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from source.read_amplitudes import read_amplitudes, fix_operator_num_args, get_tree, fix_tree, fix_subscript, fix_subscripts, read_amplitudes_and_squares\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EDUHCTk_AKa8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-WbL192AKa8"
      },
      "source": [
        "# Reading in Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhJwRNokAKa9",
        "outputId": "c3b7a3be-82a8-4f76-bc50-c8970b792f45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['notebooks',\n",
              " 'README.md',\n",
              " 'env.yml',\n",
              " 'dev',\n",
              " 'source',\n",
              " 'models',\n",
              " '.ipynb_checkpoints']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GGzjopcfAKa9"
      },
      "outputs": [],
      "source": [
        "amplitudes_file = \"../data.nosync/QED_amplitudes_TreeLevel_UpTo3to3.txt\"\n",
        "sqamplitudes_file = \"../data.nosync/QED_sqamplitudes_TreeLevel_UpTo3to3.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g8BWBW6FAKa-"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "with open(amplitudes_file, 'r') as f:\n",
        "    for line in f.readlines() :\n",
        "        line = line.split(\";\")\n",
        "        # have to remove new line character for some reason\n",
        "        line[-1] = line[-1].replace(\"\\n\", \"\")\n",
        "        # line = tf.strings.join(['[START]', line, '[END]'], separator=' ')\n",
        "        X.append(['[START]'] + line + ['[END]'])\n",
        "\n",
        "y = []\n",
        "with open(sqamplitudes_file, 'r') as f:\n",
        "    for line in f.readlines() :\n",
        "        line = line.split(\";\")\n",
        "        # have to remove new line character for some reason\n",
        "        line[-1] = line[-1].replace(\"\\n\", \"\")\n",
        "        y.append(['[START]'] + line + ['[END]'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1mvr_ndXAKa-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ONnK6W_ZAKa-"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGlFIj0OAKa_",
        "outputId": "f7328c33-b7f7-4e32-a59f-038d8944df43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[START]',\n",
              " 'Prod',\n",
              " '1/162',\n",
              " 'Prod',\n",
              " 'i',\n",
              " 'Prod',\n",
              " 'Pow',\n",
              " 'e',\n",
              " '4',\n",
              " 'Prod',\n",
              " 'Pow',\n",
              " 'Sum',\n",
              " 'Pow',\n",
              " 'm_s',\n",
              " '2',\n",
              " 'Sum',\n",
              " 's_23',\n",
              " 'Prod',\n",
              " '1/2',\n",
              " 'reg_prop',\n",
              " '-1',\n",
              " 'Prod',\n",
              " 'Pow',\n",
              " 'Sum',\n",
              " 'Pow',\n",
              " 'm_s',\n",
              " '2',\n",
              " 'Sum',\n",
              " 's_12',\n",
              " 's_13',\n",
              " 'Prod',\n",
              " '-1',\n",
              " 's_15',\n",
              " 's_23',\n",
              " 'Prod',\n",
              " '-1',\n",
              " 's_25',\n",
              " 'Prod',\n",
              " '-1',\n",
              " 's_35',\n",
              " 'Prod',\n",
              " '1/2',\n",
              " 'reg_prop',\n",
              " '-1',\n",
              " 'Prod',\n",
              " 'Pow',\n",
              " 'Sum',\n",
              " 's_15',\n",
              " 'Prod',\n",
              " '-1/2',\n",
              " 'reg_prop',\n",
              " '-1',\n",
              " 'Sum',\n",
              " 'Prod',\n",
              " 'p_1',\n",
              " 'alpha_44',\n",
              " 'Prod',\n",
              " 'p_1',\n",
              " 'alpha_5',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_33',\n",
              " 'alpha_13',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_21',\n",
              " 'alpha_48',\n",
              " 'alpha_49',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_2',\n",
              " 'alpha_5',\n",
              " '(p_5)',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_3',\n",
              " 'alpha_21',\n",
              " '(p_6)',\n",
              " 'Prod',\n",
              " 'd^(*)',\n",
              " 'i_1',\n",
              " 'alpha_48',\n",
              " '(p_1)_v',\n",
              " 'Prod',\n",
              " 'd',\n",
              " 'i_4',\n",
              " 'alpha_49',\n",
              " '(p_4)_v',\n",
              " 'Prod',\n",
              " 's',\n",
              " 'i_5',\n",
              " 'alpha_13',\n",
              " '(p_2)_u',\n",
              " 's^(*)',\n",
              " 'i_0',\n",
              " 'alpha_33',\n",
              " '(p_3)_v',\n",
              " 'Sum',\n",
              " 'Prod',\n",
              " '1/2',\n",
              " 'Prod',\n",
              " 'p_1',\n",
              " 'alpha_5',\n",
              " 'Prod',\n",
              " 'p_2',\n",
              " 'alpha_6',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_34',\n",
              " 'alpha_30',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_27',\n",
              " 'alpha_57',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_21',\n",
              " 'alpha_39',\n",
              " 'alpha_22',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_6',\n",
              " 'alpha_30',\n",
              " 'alpha_39',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_2',\n",
              " 'alpha_5',\n",
              " '(p_5)',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_3',\n",
              " 'alpha_21',\n",
              " '(p_6)',\n",
              " 'Prod',\n",
              " 'd^(*)',\n",
              " 'i_1',\n",
              " 'alpha_34',\n",
              " '(p_1)_v',\n",
              " 'Prod',\n",
              " 'd',\n",
              " 'i_4',\n",
              " 'alpha_22',\n",
              " '(p_4)_v',\n",
              " 'Prod',\n",
              " 's',\n",
              " 'i_5',\n",
              " 'alpha_57',\n",
              " '(p_2)_u',\n",
              " 's^(*)',\n",
              " 'i_0',\n",
              " 'alpha_27',\n",
              " '(p_3)_v',\n",
              " 'Prod',\n",
              " '1/2',\n",
              " 'Prod',\n",
              " 'p_1',\n",
              " 'alpha_5',\n",
              " 'Prod',\n",
              " 'p_3',\n",
              " 'alpha_6',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_12',\n",
              " 'alpha_62',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_28',\n",
              " 'alpha_10',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_21',\n",
              " 'alpha_63',\n",
              " 'alpha_18',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_6',\n",
              " 'alpha_62',\n",
              " 'alpha_63',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_2',\n",
              " 'alpha_5',\n",
              " '(p_5)',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_3',\n",
              " 'alpha_21',\n",
              " '(p_6)',\n",
              " 'Prod',\n",
              " 'd^(*)',\n",
              " 'i_1',\n",
              " 'alpha_12',\n",
              " '(p_1)_v',\n",
              " 'Prod',\n",
              " 'd',\n",
              " 'i_4',\n",
              " 'alpha_18',\n",
              " '(p_4)_v',\n",
              " 'Prod',\n",
              " 's',\n",
              " 'i_5',\n",
              " 'alpha_10',\n",
              " '(p_2)_u',\n",
              " 's^(*)',\n",
              " 'i_0',\n",
              " 'alpha_28',\n",
              " '(p_3)_v',\n",
              " 'Prod',\n",
              " '-1/2',\n",
              " 'Prod',\n",
              " 'p_1',\n",
              " 'alpha_44',\n",
              " 'Prod',\n",
              " 'p_5',\n",
              " 'alpha_58',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_60',\n",
              " 'alpha_31',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_58',\n",
              " 'alpha_64',\n",
              " 'alpha_65',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_5',\n",
              " 'alpha_37',\n",
              " 'alpha_64',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_21',\n",
              " 'alpha_65',\n",
              " 'alpha_11',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_2',\n",
              " 'alpha_5',\n",
              " '(p_5)',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_3',\n",
              " 'alpha_21',\n",
              " '(p_6)',\n",
              " 'Prod',\n",
              " 'd^(*)',\n",
              " 'i_1',\n",
              " 'alpha_37',\n",
              " '(p_1)_v',\n",
              " 'Prod',\n",
              " 'd',\n",
              " 'i_4',\n",
              " 'alpha_11',\n",
              " '(p_4)_v',\n",
              " 'Prod',\n",
              " 's',\n",
              " 'i_5',\n",
              " 'alpha_31',\n",
              " '(p_2)_u',\n",
              " 's^(*)',\n",
              " 'i_0',\n",
              " 'alpha_60',\n",
              " '(p_3)_v',\n",
              " 'Prod',\n",
              " '1/2',\n",
              " 'Prod',\n",
              " 's_15',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_42',\n",
              " 'alpha_23',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_59',\n",
              " 'alpha_3',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_5',\n",
              " 'alpha_2',\n",
              " 'alpha_42',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_21',\n",
              " 'alpha_23',\n",
              " 'alpha_38',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_2',\n",
              " 'alpha_5',\n",
              " '(p_5)',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_3',\n",
              " 'alpha_21',\n",
              " '(p_6)',\n",
              " 'Prod',\n",
              " 'd^(*)',\n",
              " 'i_1',\n",
              " 'alpha_2',\n",
              " '(p_1)_v',\n",
              " 'Prod',\n",
              " 'd',\n",
              " 'i_4',\n",
              " 'alpha_38',\n",
              " '(p_4)_v',\n",
              " 'Prod',\n",
              " 's',\n",
              " 'i_5',\n",
              " 'alpha_3',\n",
              " '(p_2)_u',\n",
              " 's^(*)',\n",
              " 'i_0',\n",
              " 'alpha_59',\n",
              " '(p_3)_v',\n",
              " 'Prod',\n",
              " '-1/2',\n",
              " 'Prod',\n",
              " 'p_1',\n",
              " 'alpha_5',\n",
              " 'Prod',\n",
              " 'p_5',\n",
              " 'alpha_58',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_43',\n",
              " 'alpha_32',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_50',\n",
              " 'alpha_16',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_58',\n",
              " 'alpha_47',\n",
              " 'alpha_43',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_21',\n",
              " 'alpha_32',\n",
              " 'alpha_68',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_2',\n",
              " 'alpha_5',\n",
              " '(p_5)',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_3',\n",
              " 'alpha_21',\n",
              " '(p_6)',\n",
              " 'Prod',\n",
              " 'd^(*)',\n",
              " 'i_1',\n",
              " 'alpha_47',\n",
              " '(p_1)_v',\n",
              " 'Prod',\n",
              " 'd',\n",
              " 'i_4',\n",
              " 'alpha_68',\n",
              " '(p_4)_v',\n",
              " 'Prod',\n",
              " 's',\n",
              " 'i_5',\n",
              " 'alpha_16',\n",
              " '(p_2)_u',\n",
              " 's^(*)',\n",
              " 'i_0',\n",
              " 'alpha_50',\n",
              " '(p_3)_v',\n",
              " 'Prod',\n",
              " '-1/4',\n",
              " 'Prod',\n",
              " 'p_2',\n",
              " 'alpha_6',\n",
              " 'Prod',\n",
              " 'p_5',\n",
              " 'alpha_58',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_67',\n",
              " 'alpha_20',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_8',\n",
              " 'alpha_0',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_58',\n",
              " 'alpha_17',\n",
              " 'alpha_67',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_5',\n",
              " 'alpha_1',\n",
              " 'alpha_17',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_21',\n",
              " 'alpha_55',\n",
              " 'alpha_7',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_6',\n",
              " 'alpha_20',\n",
              " 'alpha_55',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_2',\n",
              " 'alpha_5',\n",
              " '(p_5)',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_3',\n",
              " 'alpha_21',\n",
              " '(p_6)',\n",
              " 'Prod',\n",
              " 'd^(*)',\n",
              " 'i_1',\n",
              " 'alpha_1',\n",
              " '(p_1)_v',\n",
              " 'Prod',\n",
              " 'd',\n",
              " 'i_4',\n",
              " 'alpha_7',\n",
              " '(p_4)_v',\n",
              " 'Prod',\n",
              " 's',\n",
              " 'i_5',\n",
              " 'alpha_0',\n",
              " '(p_2)_u',\n",
              " 's^(*)',\n",
              " 'i_0',\n",
              " 'alpha_8',\n",
              " '(p_3)_v',\n",
              " 'Prod',\n",
              " '-1/4',\n",
              " 'Prod',\n",
              " 'p_3',\n",
              " 'alpha_6',\n",
              " 'Prod',\n",
              " 'p_5',\n",
              " 'alpha_58',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_56',\n",
              " 'alpha_36',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_45',\n",
              " 'alpha_51',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_58',\n",
              " 'alpha_19',\n",
              " 'alpha_56',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_5',\n",
              " 'alpha_24',\n",
              " 'alpha_19',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_21',\n",
              " 'alpha_54',\n",
              " 'alpha_40',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_6',\n",
              " 'alpha_36',\n",
              " 'alpha_54',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_2',\n",
              " 'alpha_5',\n",
              " '(p_5)',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_3',\n",
              " 'alpha_21',\n",
              " '(p_6)',\n",
              " 'Prod',\n",
              " 'd^(*)',\n",
              " 'i_1',\n",
              " 'alpha_24',\n",
              " '(p_1)_v',\n",
              " 'Prod',\n",
              " 'd',\n",
              " 'i_4',\n",
              " 'alpha_40',\n",
              " '(p_4)_v',\n",
              " 'Prod',\n",
              " 's',\n",
              " 'i_5',\n",
              " 'alpha_51',\n",
              " '(p_2)_u',\n",
              " 's^(*)',\n",
              " 'i_0',\n",
              " 'alpha_45',\n",
              " '(p_3)_v',\n",
              " 'Prod',\n",
              " '-1/2',\n",
              " 'Prod',\n",
              " 'p_1',\n",
              " 'alpha_5',\n",
              " 'Prod',\n",
              " 'p_5',\n",
              " 'alpha_6',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_35',\n",
              " 'alpha_25',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_52',\n",
              " 'alpha_61',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_21',\n",
              " 'alpha_66',\n",
              " 'alpha_53',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_6',\n",
              " 'alpha_25',\n",
              " 'alpha_66',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_2',\n",
              " 'alpha_5',\n",
              " '(p_5)',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_3',\n",
              " 'alpha_21',\n",
              " '(p_6)',\n",
              " 'Prod',\n",
              " 'd^(*)',\n",
              " 'i_1',\n",
              " 'alpha_35',\n",
              " '(p_1)_v',\n",
              " 'Prod',\n",
              " 'd',\n",
              " 'i_4',\n",
              " 'alpha_53',\n",
              " '(p_4)_v',\n",
              " 'Prod',\n",
              " 's',\n",
              " 'i_5',\n",
              " 'alpha_61',\n",
              " '(p_2)_u',\n",
              " 's^(*)',\n",
              " 'i_0',\n",
              " 'alpha_52',\n",
              " '(p_3)_v',\n",
              " 'Prod',\n",
              " '1/4',\n",
              " 'Prod',\n",
              " 'p_5',\n",
              " 'alpha_58',\n",
              " 'Prod',\n",
              " 'p_5',\n",
              " 'alpha_6',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_15',\n",
              " 'alpha_4',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_44',\n",
              " 'alpha_14',\n",
              " 'alpha_41',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_58',\n",
              " 'alpha_46',\n",
              " 'alpha_15',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_5',\n",
              " 'alpha_9',\n",
              " 'alpha_46',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_21',\n",
              " 'alpha_29',\n",
              " 'alpha_26',\n",
              " 'Prod',\n",
              " 'gamma',\n",
              " 'alpha_6',\n",
              " 'alpha_4',\n",
              " 'alpha_29',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_2',\n",
              " 'alpha_5',\n",
              " '(p_5)',\n",
              " 'Prod',\n",
              " 'A^(*)',\n",
              " 'i_3',\n",
              " 'alpha_21',\n",
              " '(p_6)',\n",
              " 'Prod',\n",
              " 'd^(*)',\n",
              " 'i_1',\n",
              " 'alpha_9',\n",
              " '(p_1)_v',\n",
              " 'Prod',\n",
              " 'd',\n",
              " 'i_4',\n",
              " 'alpha_26',\n",
              " '(p_4)_v',\n",
              " 'Prod',\n",
              " 's',\n",
              " 'i_5',\n",
              " 'alpha_41',\n",
              " '(p_2)_u',\n",
              " 's^(*)',\n",
              " 'i_0',\n",
              " 'alpha_14',\n",
              " '(p_3)_v',\n",
              " '[END]']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ACcZpcWYAKa_",
        "outputId": "21553f3b-7eec-4da6-d729-884bb0ec5555"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9647049950>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgU1b3/8feXxRFFAwgisggqLiiCOILGJS65gqBBcxOj5iZqSDBRb4w/bwxmkxiNRK9RE7doJC4xoonmBhVFVBR3GJAd0QGGZWQZWQcGZj2/P7p66Jnp7unu6aW66/N6nnmmu7qq+pxaPnXqVHW3OecQEZHgaJfrAoiISHYp+EVEAkbBLyISMAp+EZGAUfCLiARMh1wXIJ7u3bu7/v3757oYIiJ5Ze7cuV8453rEet3Xwd+/f39KSkpyXQwRkbxiZqvjva6uHhGRgFHwi4gEjIJfRCRgFPwiIgGj4BcRCRgFv4hIwCj4RUQCRsHfirr6Bp6bs5aGBkdFZTUNDS2/xnrHnlqmLvg86vSVe2qpqqmjfNtuZn6yKeH3raqpo3JPbdTX/u/jcnZV1zU+X7B2G3tq62locDz27qqY0yVrx55alq3f0aJcOyPeO1E7q+ualDmeZet3MHf1FmrrG9iyqyahafbU1rN99956b95ZzdZdNbwYY70459hUuSf6fKratvy2VdVQU9cANF1e05dsoKKyOu60u2vq2RGx/tZtraJ8224gtAyrakLzilb2VC0u395knc5cvokln29vMs6qL3Y1vueiddtZs7mq1flGlre58P7U3LaqGj7dWNlk2LL1O5qsW4Atu2qorW+I+/5VNXUsLm9aj+27a9lTW8+2qhqq6+qTLjfA2i1VfO6tk1gWl29ny66aJusSWq637btrWbul9WWZbr7+AFcm7K6p59hfv8o1Zx3BTaOOAaC6LrSzb99dy8CeBzSO23/Cy42Pl67fwePvl/HTkUfzvdMGYAb7dmzP1l013PT8QmYs3cj1Uz5m0cSRLFi7jQHd9+fQLp0YPPE1DijqAAaVe+oomzSGTzdW0rtLJ7bsCm18Rx58AB+u3EzvLp2A0HzPvHMmu2vrWX7bKG58bgE3jTyGfgftx8drtvKTZ+fz9RN784dvDWXD9j2MfeC9JnX87UtLKZs0BoBR987ikuK+bN5VzQMzVzSO89ORR3Pt2UdGXUZ7autxDr7zl49YsG5747wABv16euPjm0YdzajjDuHwHp0bh9XWN/DywvUM7NmZMX98lynjT+GDFZu5743PaGew8o7QvF5c8DmHdunESYd1ZWd1HR3bG0Ud2rOtqobz73sHgK8P680L88opvf18OrRvx+Ly7RzRozM//NtcenftxO8uHtxY3lH3zqJscxVlk8ZQuaeWk257vbFMxx16IId26UR9g2P/otAm/9SHq/n1v5cw/SdncvQhe9f5Nx/+gEVeWPz4nCP5f+cdjXOObVW1/Oz5hby2dCOf/HYU+3Zs3zhNXX0Dy9ZXMrjPlwAYeusMhvT5EvdfPoxz//A2NXUN/HLMsdz28jIAVvxuNA3OMeQ3r3HH1wdz1lEH03nfDrRvZxz761cBGpf56b+f2fj8+FtCy37ihYOY+OJSbr/4eCoqq7nqtAF8qVNHALbuqqHr/vuwsmInn2/bQ3H/rk3K+sDMUu6avpxPbzuffTq0o6augQv+9C6nHXkQT3//FLbvruWqv84B4LUbzmR3TT1D+nbh7P99C4CFE8/jwvvfBeDNG79C9wOKWLO5iiN6dGbDjj3c/MJC2rcz3ivdDMA+Hdrx4OXD+P6TJfz9ByN48v3VfP+MAbyyeAOPvbuKd246m77d9mss39fuf481W6p4atxwFq7bTlGHdtz28jKOO/RAXv7xGXyyYQd9uu7HsN/OaNwH1m/fTeWeOg7vvj8d2u9ty4a31cW/GUlnb70P+c1rja+fevhBPDP+FOobHFMXlDN2SG/atTOOv2U67dsZ8371H3ypU0c276zmi501bKrcwzV/m0eld5AsmzSG3TX1TH5vFVd8uT/H3zKdngcWsXFH0wNaeF2+X/oFl//lIx7+r2GMOr5Xk/Lc/c0hnHlUD/bt2I59O7anY/vMtskDF/zhBf3gWyvYsquGKXPW0mW/jmzzWnn3XTqUPl07cce0T5pM9/j7ZQA8+s5K7pq+HIAbvnoU97z+aeM4ztG4cx5Q1IGfnR86sFRGtKYaGhzn3TOLUw8/iA9WhnaO1244k0sf+TBqeY/+ZSgIKvfU8cT3hrOrOtRK2ei1HHZWR2+d9p/wMkt+M5JPNlRy60tLW7z+6DsrWwT/oF+/yleO6sEbyzZRE6U19frSjU2e3/nqcu58dXmTA8PDb63g7hl7l8m/53/OM7PXhOoecbL03898DMAZA7vzzmdfADDrp2dz5l0zG8d5acF6AOqd4/PNVVzwp3ebvP+qil08M/4UzrtnFmsiWk2Ve5q21vbUNjDy3lms9g4MAO967/mnNz/jpYXrueGrR7GzurYx9AEefnsl+xd14I5Xmm4Lx/zqVf78nZN46K0VfLO4D2u37Obht0MH1U9vOx+ABeu2c8ade+sSDn2A+98sbdxurp8yn2hemLeOsohWdWQjZOKLofX5i38tBuDe1z9jWL8uzFuzDYAfnXUED7219yB/wQm9uP/yYQD82Svn5l3VnHrHm43jlJRtZfPOatZu3duSPe+eWQA8ftXJjcP+WbKu8fHarbs55+63Q+MO6slrzbYPgJq6Br7/ZOjT95c/+hEAry7Z0Pj6+u176NttP8Y9Pod5a7ay1dsPv/PY7CbzWfL5DnZW1zHq3ncah720cD1XnTag8UB0SXEf7vzGkBZlOP33b3LuMT0bD45hH6zcTP8JL3PZ8H48M3sNd726nPdvPheA+gbX5CARS/hAHc6E5qEfFrn+5q3Z1hj8YTf+Y0Hj4zMGduepcSNafe+2CFzwRwbalDlrARpDH2LviGGR40aGfnOV1XX88v8Wtxgezr6PVm1uHLayYmfc90zVTf9cmNT4VTX1vLJ4Q8zXyzbvanUeG5udym5tpasmHPoAa7fGPuXdWtVyPuED55oETpVXx+iaeGlh6OASa10+GBGgka5+ai4A89du4/QjuzcO310TvfsgUvPus2j+33MLWh0nUjj0gSahD6E63n950/E372y5PCPPkiJd6Z0BwN5l3ly00E/GGwl0g1bXtly2D8wsbXz8XMm6qMG/raqW5+etazE87P8+Lgfg8+3p6z5ri8h9IlPUx1/AVm9pPahFJHgU/CIiAaPgFxEJGAV/QLmWd6WKSEAo+EUkLznUekmVgj/PpGtjN0vLbFrQmUTrFFiSawr+PGVkKLkLkIK2MGkfSJ2C3xdS34DjtbAjX0tHC99SmEk+h25KZVcWZVU+b1+5pOAXkYSl+7jm1DeYEwp+yah8368zdS2kECi085eCP6C0zwZTKt11TadPU0F8JNvdRX5YhK0Gv5n1NbOZZrbUzJaY2fXe8IlmVm5m872/0RHT3GxmpWa23MxGRgwf5Q0rNbMJmamSRKOgz5xCDMN8oP791CXyJW11wI3OuXlmdgAw18xmeK/d45z738iRzWwQcClwHHAo8LqZHeW9/ADwH8A6YI6ZTXXOtfzqSMk4hZVIcLUa/M659cB673GlmS0DeseZZCwwxTlXDawys1JguPdaqXNuJYCZTfHGVfAnwe8td58Xzxf8vg6l8CXVx29m/YETgY+8QdeZ2UIzm2xmXb1hvYG1EZOt84bFGt78PcabWYmZlVRUVCRTvLyVSus7kWkKJWAKpR6SXvl6H78fNueEg9/MOgPPAz9xzu0AHgKOAIYSOiO4Ox0Fcs494pwrds4V9+jRIx2zlHyVpv06mwcOdaFJPkjoh1jMrCOh0H/aOfcCgHNuY8TrjwIveU/Lgb4Rk/fxhhFnuGSYWdMATCUMlWnit1Z2Og7qQTyjTOSuHgMeA5Y55/4QMTzyt8MuBsI/NzUVuNTMisxsADAQmA3MAQaa2QAz24fQBeCp6alGcAVwm21VIq3uIHWVFap03dUTxNWcSIv/NOA7wCIzC/8u4c+By8xsKKHlVgZcDeCcW2JmzxG6aFsHXOucqwcws+uA6UB7YLJzbkka6yIiBaytn0GQvRK5q+ddop/lT4szze3A7VGGT4s3nWSP9qHEaDFJIdIndyWt/NA94ocy+J1fDvxaVbmh4M8z+baj5Ft5s8GPyyTRMkUeMPxYD0mMgt8Hkml8hb8YK5H+zng7plrFmeGThnSrCmH9++0Oo0T5odQKfpEA8UsXj+SWgj8g0rG/KzTET5y+pi1lCn4RSZgO/oVBwR8QzVtG2oFFgkvBn+f8fpHO7+WLJ4+L3iod+INNwS9pVshxmR75fDCUwqDg94FkPoqersxQ+CRGXxMghUjBn6cSiSP9GHb26UCRPfl6H78f9koFv4jkTFvaJrqZM3UKfil4OvGRuAK4fSj4AyItH+BKaarU96r8PJEvbH7rXtFBPTUK/oDyY1e0duI8k+X1lalrVkHsMlLwB1Qhh2xCv8CVxpZr5AVdv19Qb2utCzEks73K/NDmUvDnG5/vdy13Ij9s5qlxzuVx6QuP7phKHwV/jkTmYyqbs1/3gba0nvxaJ5FCo+DPsmjZ1pbA8/+pt9/Ll15qlWaXFndqFPwicShYpBAp+AMiWO1uEYlHwS8Jy9duDP93h2Wf3+7HT5XPb6LyLQV/QBTGbi65VigHjKBT8Eta+aF17f9WoO8LmDW+2F5yXYAcUPDnGT/sKBJgavAXBAW/D6TSdZ4v+5//W9/plS/rRfYK4jpT8OeZZII0aKGbboFafClUVmef+UvBn6fy9Q4byS1tNwIJBL+Z9TWzmWa21MyWmNn13vBuZjbDzD7z/nf1hpuZ/dHMSs1soZkNi5jXFd74n5nZFZmrVnD4vVXv8+KlhaJU8k0iLf464Ebn3CDgFOBaMxsETADecM4NBN7wngOcDwz0/sYDD0HoQAHcAowAhgO3hA8WIvHk9uCmWJfC02rwO+fWO+fmeY8rgWVAb2As8IQ32hPARd7jscCTLuRDoIuZ9QJGAjOcc1ucc1uBGcCotNZGYkrHKX62ewnUKyGtC8I5Zfol1cdvZv2BE4GPgJ7OufXeSxuAnt7j3sDaiMnWecNiDW/+HuPNrMTMSioqKpIpnviA37ue/CCXy6itvxegY3FhSDj4zawz8DzwE+fcjsjXXGhrSsvm7Jx7xDlX7Jwr7tGjRzpm6XvJfBpSwSrpUAhnU9oXUpdQ8JtZR0Kh/7Rz7gVv8EavCwfv/yZveDnQN2LyPt6wWMMlBQWw3xakQgjUoAni8SORu3oMeAxY5pz7Q8RLU4HwnTlXAP+OGP5d7+6eU4DtXpfQdOA8M+vqXdQ9zxsmGRJ5n3WufhIwXTmYTOkT+unFgAe0b+rvgx/u8fvPZWZChwTGOQ34DrDIzOZ7w34OTAKeM7NxwGrgEu+1acBooBSoAq4CcM5tMbPfAnO88W51zm1JSy1EpG38ciCII1NFDF7sJxD8zrl3ib3Mz40yvgOujTGvycDkZAookisBbAi2Sh8AKwz65K5klLJTxH8U/FmW7iDMZqs0kbZe8+L4tf80p7dU5u6tG/l0tSSlEOqQKwr+HEn2hLmtZ9jpOEXP1/2sLQFRaD0b4e0g1WXit8WRl+Hvg4Wo4PeDJDaE5tt5qsHk15Z4Piq0g4MUPgV/nkokbPyQ7T4oQlbly08TFsLBqhDqkCsK/oDS3RkiwaXgL2DKdhEf8sFpsIJfRCRgFPwikpf8cA0rXyn4Ja0ysTMm+9uufg8E3VG1l5ZEbij4fSAXXfGphE+2y5kvd8gEid+uG+nAkRoFf55pHtiJ5neu9lc/NG59UATfSTXAfZb7kiIFf95qfReMDN2WH/zKzi6cTOj64SAh+cNvZx/5RMGfZ5SN2VWo2dLiIJvghhU5WrYP1Nr200fBn6fU2vGnZC9EZ1tbN5tCPCvLep18sO8q+CWjfLCNZ1wQ6uhHhXgQyhYFf0Bl6pZCP7R40/nTizqz8g+tivRR8IuIBIyC3wfy5gvTMlzOfFkMhUDLOtgU/HkmXT00GTvY5L6nR0RaoeDPkbbmY7I/gxjkBp6+IiF90t1e0K+j5YaC3wfasv364WJqPP4unUgwKfgDSq1gSYWfGtnahFOn4BeJQ18UJ2nngwOWgl/SqsU3AahZ1oKWiOSagt8HdJFKsi0dZzI6pucvBX9A5OrbOcWf/H5TQEHzwa7XavCb2WQz22RmiyOGTTSzcjOb7/2NjnjtZjMrNbPlZjYyYvgob1ipmU1If1WCInc7bJC/0z+efDqI5lFRJYMSafE/DoyKMvwe59xQ728agJkNAi4FjvOmedDM2ptZe+AB4HxgEHCZN66kKJEdOLJ/vfno+dD3rpDyHz8d5MzyYzv2ow6tjeCcm2Vm/ROc31hginOuGlhlZqXAcO+1UufcSgAzm+KNuzTpEoskSdFQmJT5qWtLH/91ZrbQ6wrq6g3rDayNGGedNyzW8BbMbLyZlZhZSUVFRRuKJyIi0aQa/A8BRwBDgfXA3ekqkHPuEedcsXOuuEePHumarWRJEE+9g1hnyW+tdvVE45zbGH5sZo8CL3lPy4G+EaP28YYRZ7i0QSFnTqp18/sy8UP59MG0YEupxW9mvSKeXgyE7/iZClxqZkVmNgAYCMwG5gADzWyAme1D6ALw1NSLXVhysRP66SJda8xyd0dRHi0mkYS12uI3s2eAs4DuZrYOuAU4y8yGErpuVgZcDeCcW2JmzxG6aFsHXOucq/fmcx0wHWgPTHbOLUl7bURI7y9wSVNabIUhkbt6Losy+LE4498O3B5l+DRgWlKlkxbS1U2QSr+0wlJySdtf+uiTu3kqke4hH3Qli2SUtvHUKPjzRFtb+kFuLfnhYmrBCPB2VEgU/HlGGSaZkMp392hbzF8K/jzl1xZ8EMMg2TukcruMfLrhSFYp+AOieXdHPt3OKSLppeD3gVxkcLY+bar+dRH/UfCLSF5SmyJ1Cv48k8sWdBA/5h+8GmeXfhAmNxT8eSqh7qEC2afUXSTR6KCcOgW/+JauP/uP38761ChIjYI/IIIdokqH5lLdHoK9HRUOBb+kVfMWmPpwW8rt9/drfYiC3xfUiArJXB5qCTenJRJsCn4RyUs6d0mdgl8kjfLlYmOqxYysX7a7rPJl2eYDBX+eUZ+5/+RXt0nbSqvtr+38cGeUgj9PhTeeeK2gdO+iQbyjQ99p5F9aM6lT8EvBSaRF5YdWVy4VSu11/pEaBb+kVaZ2RO3g/pDLA6ZOvtJHwS8Fp2U/tA4brclVoOuCbW4o+P1ALRlALTpJTr4eM/xwgVzBLyIJ08G5MCj4Ja1y+3UEIpIIBX+OpJqPyUznhxD2QRGkgOkEJDUKfh9I6cJaDrZ47WTiJ9oeU6fgl4xKR4s/EycNfrjAJpIrCv4sa2v3S8sbFf0VYOksjVp0meP37ShR+Vnq3FPw50jk3RGJ3CnRfJxkQzEd92nn605WV596yQvtLpZwfVJtf/hpceTr9hjeFxsaYtegtr4hs2VorQVqZpOBC4BNzrnjvWHdgGeB/kAZcIlzbquFvtjkPmA0UAVc6Zyb501zBfBLb7a3OeeeaK1wxcXFrqSkJIVqwdBbX2NbVS0Aw/p1oXzbbjbuqE5pXunUvXMRX+xsWo7eXTpRvm13QtN/+YiDeH/FZgCuO/tIZn1WwcJ121Mqyy9GH8vt05YxduihXH/uQM65++2o4102vB/PzF4Td177dGhHTV3rG+uT3xvOBys389BbKxIu57B+XVhUvp3aKAF+06ijufPV5QnP62/jRvDSws+ZMmdtwtMkY8zgXry8aH1G5p1OV595OH+etTLXxWD04EP4z2F9GPdEavt5uv39ByO4/NGPEhr3wW8P45qn57U63n8O68Pz89Y1GXbhkEN5ccHncadb/JuRdC7qkFBZmjOzuc654pivJxD8ZwI7gScjgv9OYItzbpKZTQC6Oud+Zmajgf8mFPwjgPuccyO8A0UJUEzoQD0XOMk5tzXee6ca/M45Btw8LenpRET8pGzSmJSmay34W+3qcc7NArY0GzwWCLfYnwAuihj+pAv5EOhiZr2AkcAM59wWL+xnAKOSq4qIiKRDqn38PZ1z4fPZDUBP73FvIPIcep03LNbwFsxsvJmVmFlJRUVFisUTEZFY2nxx14X6itJ2ncU594hzrtg5V9yjR490zVZERDypBv9GrwsH7/8mb3g50DdivD7esFjDRUQky1IN/qnAFd7jK4B/Rwz/roWcAmz3uoSmA+eZWVcz6wqc5w0TEZEsa/VeITN7BjgL6G5m64BbgEnAc2Y2DlgNXOKNPo3QHT2lhG7nvArAObfFzH4LzPHGu9U51/yCsYiIZEGrwe+cuyzGS+dGGdcB18aYz2RgclKlS5G+GExEJDZ9cldEJGAU/CIiAaPgFxEJGAW/iEjAKPhFRAJGwS8iEjAKfhGRgCnI4Ndt/CIisRVk8IuISGwKfhGRgFHwi4gEjIJfRCRgFPwiIgGj4BcRCZiCDH6n72UWEYmpIINfRERiU/CLiASMgl9EJGAU/CIiAVOQwV9VW5/rIoiI+FZBBv+eGgW/iEgsBRn8IiISm4JfRCRgFPwiIgGj4BcRCZjCDH7LdQFERPyrMINfRERialPwm1mZmS0ys/lmVuIN62ZmM8zsM+9/V2+4mdkfzazUzBaa2bB0VCBqudTkFxGJKR0t/rOdc0Odc8Xe8wnAG865gcAb3nOA84GB3t944KE0vHdUTj+3LiISUya6esYCT3iPnwAuihj+pAv5EOhiZr0y8P4iIhJHW4PfAa+Z2VwzG+8N6+mcW+893gD09B73BtZGTLvOG9aEmY03sxIzK6moqEipUOrqERGJrUMbpz/dOVduZgcDM8zsk8gXnXPOzJLqd3HOPQI8AlBcXKw+GxGRNGtTi985V+793wT8CxgObAx34Xj/N3mjlwN9Iybv4w1LO1ODX0QkppSD38z2N7MDwo+B84DFwFTgCm+0K4B/e4+nAt/17u45Bdge0SUkIiJZ0paunp7AvyzUvO4A/N0596qZzQGeM7NxwGrgEm/8acBooBSoAq5qw3vHpQa/iEhsKQe/c24lMCTK8M3AuVGGO+DaVN9PRETSQ5/cFREJGAW/iEjAKPhFRAKmIIPfdD+niEhMBRn8IiISm4JfRCRgCjL41dEjIhJbQQa/iIjEpuAXEQkYBb+ISMAUZPDrbk4RkdgKMvhFRCQ2Bb+ISMAUZPDrpxdFRGIryOBv317BLyISS0EGf+eitv6UsIhI4SrI4BcRkdgU/CIiAaPgFxEJGAW/iEjAKPhFRAJGwS8iEjAKfvGNYf265LoIIoFQsMFfNmlMUuO39sVukfMrmzSGEyNCKtn3iuXYXgemNN3/fnNIq+P89aqTmzxPpcxD+rYM5rJJYyibNIYrv9y/1enLJo3hqJ6dY77+wjWnxZx/tGHt2+1daV8f1rvFtKvuGN04bqL1Pe7QA6OOm+x8UlXUoV3j+/zu4sFtmte5xxzc5Hmy5Y8c952bzk5o2q77dWwxbODBe9f5ny47sdX3CpezT9dOCZcVYNRxhzQ+fmrc8FbHP7l/17ivR1teHWN8OPTiE1tuf2ETzj+GVXeMbvW9Tsxiw6dggz9Zg5IMXefSXwaXiZl62qXhK0vT8XnodH6dRrtWZmUp1DnX3+yajvUEcNhB+9HvoP3SMi9IfLlEK3+qVUp2WUSO3qXTPq2On8rulsr229p2mgsKfs/fxo2I+drkK4uzUoaGjAZ/2+cRbz9MdB91pK+OmfxOpu+eeljC4x5y4L5xX3/sisS3n8izmFQDs6hDO1740Zf58TkDG4e9eeNXUppXsttNuygThNfTw/91UlrfO95Z5uA+X2p1/g7oEuUMBUj6bCMew1JqhGSSgt/Tdf/YLYRzjumZlTI0ZC73o4ZktNPy+PNIbv4Zl4G3DNfjmEMSPwM86+gecV8/99jEt590VOmkw7pyUOeiJt9ZdXiP2F1s8YQPaokGV7SwDk96WJJnIK29Z/OukWSz1TlHzwPiH7RbFiq50SH3Z5HRFHTw/23cCK49+wguHHIo0LJl1t/bEH868mgA7v3WUG746lGMHnwIB+7bgXOOOZiJFw6KOu/wNNGMO31A4+Orv3I4EOo7PuTAfTmnWb9r2F+vPJlfjDm28fnlI/rxeES//PXnDow2GZ2LOjBmcC+KD9vbX1nUoeVqHT6gG984qU+TYU9+L3SW869rvsx5g1qG04/POZLLR/TjoW8Po3NRB+78xgn0PLCIC07oxcQLB3HPt/ZeW7h8RL8W059yeDcg1McZvn4RDtYzj9oblj8+50huu+j4JtP2PLCoSaCeMbA7AL+MWEZ3feOExscTRh3TZPpo/aXh7WDqdaFrCbeOPY4fnDGgyTjhnfSiEw/lwiGH0q/bfvx8dNN5N3fjebG3hfD8//79EfzorCP4xw9PbXytX7f96HlgERBaB9855TCe/sHeM8+xQ0Nl+OFXjog5/0uK+7QYFt5WDvC+s6p5y/jWscfFrU+kv1xxMpcN70cvb9+5+szDo4739++Hyv3s+FP58TlHNnnt5tHH0r1zEf0P2p//iNjOvuodEMPXn4YP6MZNo/Yuy/6tHChGHncI/4xYnr+6YBA/HXk0IwaEtrvTj+zeYprIs/f/Oe9oHvj2iZzgnR18zds+AG65cO8yCu/DAP++9jTOP/4QDopoKP7jh6cy7vQBdC7q0Lg+jznkAPp07cQFJ/Ti0uGhfeO3Fx3PXd84gV9fEMqUcDnDftpsO3ro28Pi1r8tLJP9ylHf0GwUcB/QHviLc25SrHGLi4tdSUlJWt+//4SXAfj9fw7mWye3DKtEpg1f8Il8fuuLS5n83ip+d/FgLh/Rr8W4zefTvp3x1WMPZvqSjTHHa4sps9cw4YVFXPnl/kz82t6NOF65Lnn4A2aXbeHF605P6FS5ufC8rz37CB6YuYJfXTCoyUEQYOwD77Fg7Tam/+RMRt47q0VZRt07i082VPLW/5xF/+77J/yeZZPGsHrzLr5y12gQebkAAAfASURBVFtAaAeNdjE6loXrtvG1+99j+IBuPHf1qXHHDb9nWNmkMVGHJVLmRFTuqWXwxNfocUARc37xVc66ayZlm6uazCPZeYbH/8MlQ/j6sD4typ/IvOK955V/nc1byyuYMv4UTjn8oISni3TN03OZtmgDf73yZM4+5mDe/GQj33u8hDGDe/FAkqGY7PLJlkyVy8zmOudi9zE657L2RyjsVwCHA/sAC4BBscY/6aSTXLr9+e1Sd9jPXnI1dfVJT7v08+3usXdWNj6ft3qLe/rD1c455yr31LrfvbzUVdeG5rts/Xb3l4hxIz06a4X7ZP0O90XlHveDJ+a4h98qTaEm8VXX1rvfvbzU7dhd02T4x2u2ur99WBZ1mvXbdru7X1vuGhoaUnrP15ducK8sWu92VYeWxe6auhbjlG+tcvfMCL3HnFWb3bNz1jR5fc3mXe6+1z9NuAwvzFvr3iutcM4519DQ4H7+wkJ3w7MfJ12HhoYGd/dry936bbtbHXfK7NWupGyL+9af33f3v/mZc865t5dvcl9/8D332Dsr3fNz18ad/qkPytz8NVuTKt+DM0vdik2VzjnnVn+xyw2/fYZbtG5b4+t//2i1m7t6S8LzmzJ7tRt5z9uN+8Gjs1a4219e6i744zvu8fdWuQ9XfNHqPKbOL3dvL98U9bWNO3a7u179xNXXt1wPf313pVtcvi3KVE1t3lntfv/KMlfnzaOuvsH9/pVlbvPO6lanbe6VRZ+7N5ZtSHq6TGueKekClLg4WZzVFr+ZnQpMdM6N9J7f7B187og2fiZa/CIiha61Fn+2+/h7A2sjnq/zhjUys/FmVmJmJRUVFVktnIhIEPju4q5z7hHnXLFzrrhHj/h3S4iISPKyHfzlQN+I5328YSIikiXZDv45wEAzG2Bm+wCXAlOzXAYRkUDL6o/TOufqzOw6YDqhO3wmO+eWZLMMIiJBl/VfJXfOTQOmZft9RUQkxHcXd0VEJLMU/CIiAZP1r2xIhplVAKvbMIvuwBdpKk6uFUpdCqUeoLr4leoChznnYt4P7+vgbyszK4n36bV8Uih1KZR6gOriV6pL69TVIyISMAp+EZGAKfTgfyTXBUijQqlLodQDVBe/Ul1aUdB9/CIi0lKht/hFRKQZBb+ISMAUZPCb2SgzW25mpWY2IdflicXMysxskZnNN7MSb1g3M5thZp95/7t6w83M/ujVaaGZDYuYzxXe+J+Z2RVZKvtkM9tkZosjhqWt7GZ2krdsSr1pM/aT1THqMtHMyr11M9/MRke8drNXruVmNjJieNTtzvtSwo+84c96X1CYiXr0NbOZZrbUzJaY2fXe8LxbL3Hqko/rZV8zm21mC7y6/Cbe+5tZkfe81Hu9f6p1jCnez3Pl4x9J/rxjjstaBnRvNuxOYIL3eALwe+/xaOAVwIBTgI+84d2Ald7/rt7jrlko+5nAMGBxJsoOzPbGNW/a87Ncl4nA/0QZd5C3TRUBA7xtrX287Q54DrjUe/ww8KMM1aMXMMx7fADwqVfevFsvceqSj+vFgM7e447AR94yjPr+wDXAw97jS4FnU61jrL9CbPEPB0qdcyudczXAFGBsjsuUjLHAE97jJ4CLIoY/6UI+BLqYWS9gJDDDObfFObcVmAGMynQhnXOzgC2ZKLv32oHOuQ9daIt/MmJe2apLLGOBKc65aufcKqCU0DYXdbvzWsTnAP/0po9cLmnlnFvvnJvnPa4ElhH6hbu8Wy9x6hKLn9eLc87t9J529P5cnPePXF//BM71yptUHeOVqRCDv9Wfd/QRB7xmZnPNbLw3rKdzbr33eAPQ03scq15+qm+6yt7be9x8eLZd53WBTA53j5B8XQ4Ctjnn6poNzyive+BEQq3LvF4vzeoCebhezKy9mc0HNhE6kK6I8/6NZfZe3+6VN20ZUIjBn09Od84NA84HrjWzMyNf9FpVeXm/bT6X3fMQcAQwFFgP3J3b4iTOzDoDzwM/cc7tiHwt39ZLlLrk5XpxztU754YS+tXB4cAxuSxPIQZ/3vy8o3Ou3Pu/CfgXoQ1io3dKjfd/kzd6rHr5qb7pKnu597j58Kxxzm30dtYG4FFC6waSr8tmQl0oHZoNzwgz60goKJ92zr3gDc7L9RKtLvm6XsKcc9uAmcCpcd6/scze61/yypu+DMjExYxc/hH6cZmVhC5+hC90HJfrckUp5/7AARGP3yfUN38XTS/E3ek9HkPTC3GzveHdgFWELsJ19R53y1Id+tP0gmjayk7Li4ijs1yXXhGPbyDUtwpwHE0vsK0kdHEt5nYH/IOmF/GuyVAdjFC/+73NhufdeolTl3xcLz2ALt7jTsA7wAWx3h+4lqYXd59LtY4xy5TJnSlXf4TuVviUUD/aL3JdnhhlPNxbQQuAJeFyEurLewP4DHg9Yocz4AGvTouA4oh5fY/QhZ5S4Koslf8ZQqfatYT6FMels+xAMbDYm+Z+vE+ZZ7EuT3llXUjod6EjA+cXXrmWE3FXS6ztzlvXs706/gMoylA9TifUjbMQmO/9jc7H9RKnLvm4Xk4APvbKvBj4dbz3B/b1npd6rx+eah1j/ekrG0REAqYQ+/hFRCQOBb+ISMAo+EVEAkbBLyISMAp+EZGAUfCLiASMgl9EJGD+P8cGRLynEVIoAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot([len(x) for x in X_train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RpEx9LqAKa_",
        "outputId": "30833308-6add-4661-9c8d-0d69835638a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| len(X_train_idx_okay): 19266\n",
            "ic| len(X_test_idx_okay): 4854\n"
          ]
        }
      ],
      "source": [
        "X_train_idx_okay = np.where([len(x) < 250 for x in X_train])[0]\n",
        "X_test_idx_okay = np.where([len(x) < 250 for x in X_test])[0]\n",
        "ic(len(X_train_idx_okay));\n",
        "ic(len(X_test_idx_okay));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "cUOZJ8QSAKbA"
      },
      "outputs": [],
      "source": [
        "X_train_short = [X_train[i] for i in X_train_idx_okay]\n",
        "y_train_short = [y_train[i] for i in X_train_idx_okay]\n",
        "\n",
        "X_test_short = [X_test[i] for i in X_test_idx_okay]\n",
        "y_test_short = [y_test[i] for i in X_test_idx_okay]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_text = [\" \".join(x) for x in X_train_short]\n",
        "y_train_text = [\" \".join(yy) for yy in y_train_short]\n",
        "\n",
        "X_test_text = [\" \".join(x) for x in X_test_short]\n",
        "y_test_text = [\" \".join(yy) for yy in y_test_short]"
      ],
      "metadata": {
        "id": "K5ZGOW8MpcDA"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuQguRfSAKbA"
      },
      "source": [
        "# Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SahAIg0jAKbA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oH1wQoicAKbB"
      },
      "outputs": [],
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(1000, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UIBjBFqoAKbB"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(X_train)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train_text, y_train_text)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL3yrsRfAKbB",
        "outputId": "e3d4f07c-6844-4383-ec04-a7fcd8e49c3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'[START] Prod 1/12 Prod i Prod Pow e 4 Prod Pow Sum Pow m_mu 2 Sum Prod -1 s_25 Prod 1/2 reg_prop -1 Prod Pow Sum Pow m_mu 2 Sum Prod -1 s_24 Prod -1 s_25 s_45 Prod 1/2 reg_prop -1 Prod Pow Sum Pow m_e 2 Sum Pow m_mu 2 s_12 Prod -1 s_14 Prod -1 s_15 Prod -1 s_24 Prod -1 s_25 s_45 Prod 1/2 reg_prop -1 Sum Prod p_2 alpha_9 Prod gamma alpha_9 alpha_7 alpha_21 Prod gamma alpha_3 alpha_18 alpha_7 Prod gamma alpha_3 alpha_10 alpha_14 Prod gamma alpha_5 alpha_6 alpha_2 Prod gamma alpha_5 alpha_21 alpha_8 Prod c^(*) i_0 alpha_6 (p_3)_v Prod c i_4 alpha_2 (p_6)_v Prod ee i_1 alpha_8 (p_1)_u Prod ee^(*) i_3 alpha_18 (p_4)_u Prod mu i_5 alpha_14 (p_2)_u mu^(*) i_2 alpha_10 (p_5)_u Sum Prod -2 Prod p_4 alpha_3 Prod gamma alpha_3 alpha_15 alpha_1 Prod gamma alpha_5 alpha_17 alpha_22 Prod gamma alpha_5 alpha_20 alpha_13 Prod c^(*) i_0 alpha_20 (p_3)_v Prod c i_4 alpha_13 (p_6)_v Prod ee i_1 alpha_22 (p_1)_u Prod ee^(*) i_3 alpha_17 (p_4)_u Prod mu i_5 alpha_1 (p_2)_u mu^(*) i_2 alpha_15 (p_5)_u Prod -1 Prod p_5 alpha_9 Prod gamma alpha_9 alpha_24 alpha_12 Prod gamma alpha_3 alpha_0 alpha_24 Prod gamma alpha_3 alpha_23 alpha_4 Prod gamma alpha_5 alpha_11 alpha_16 Prod gamma alpha_5 alpha_12 alpha_19 Prod c^(*) i_0 alpha_11 (p_3)_v Prod c i_4 alpha_16 (p_6)_v Prod ee i_1 alpha_19 (p_1)_u Prod ee^(*) i_3 alpha_0 (p_4)_u Prod mu i_5 alpha_4 (p_2)_u mu^(*) i_2 alpha_23 (p_5)_u [END]'\n",
            " b'[START] Prod 1/27 Prod i Prod Pow e 3 Prod Pow Sum Pow m_u 2 Sum s_13 Prod -1 s_14 Prod -1 s_34 Prod 1/2 reg_prop -1 Prod Pow Sum s_34 Prod -1/2 reg_prop -1 Sum Prod p_3 alpha_7 Prod gamma alpha_11 alpha_12 alpha_5 Prod gamma alpha_3 alpha_2 alpha_4 Prod gamma alpha_3 alpha_6 alpha_10 Prod gamma alpha_7 alpha_10 alpha_12 Prod A i_0 alpha_11 (p_3) Prod b^(*) i_4 alpha_2 (p_2)_v Prod b i_2 alpha_4 (p_5)_v Prod u^(*) i_1 alpha_6 (p_1)_v u i_3 alpha_5 (p_4)_v Prod -2 Prod p_4 alpha_11 Prod gamma alpha_3 alpha_8 alpha_1 Prod gamma alpha_3 alpha_0 alpha_9 Prod A i_0 alpha_11 (p_3) Prod b^(*) i_4 alpha_8 (p_2)_v Prod b i_2 alpha_1 (p_5)_v Prod u^(*) i_1 alpha_0 (p_1)_v u i_3 alpha_9 (p_4)_v [END]'], shape=(2,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'[START] Prod 1/12 Prod i Prod Pow e 4 Prod Pow Sum Pow m_mu 2 Sum Prod -1 s_25 Prod 1/2 reg_prop -1 Prod Pow Sum Pow m_mu 2 Sum Prod -1 s_24 Prod -1 s_25 s_45 Prod 1/2 reg_prop -1 Prod Pow Sum Pow m_e 2 Sum Pow m_mu 2 s_12 Prod -1 s_14 Prod -1 s_15 Prod -1 s_24 Prod -1 s_25 s_45 Prod 1/2 reg_prop -1 Sum Prod p_2 alpha_9 Prod gamma alpha_9 alpha_7 alpha_21 Prod gamma alpha_3 alpha_18 alpha_7 Prod gamma alpha_3 alpha_10 alpha_14 Prod gamma alpha_5 alpha_6 alpha_2 Prod gamma alpha_5 alpha_21 alpha_8 Prod c^(*) i_0 alpha_6 (p_3)_v Prod c i_4 alpha_2 (p_6)_v Prod ee i_1 alpha_8 (p_1)_u Prod ee^(*) i_3 alpha_18 (p_4)_u Prod mu i_5 alpha_14 (p_2)_u mu^(*) i_2 alpha_10 (p_5)_u Sum Prod -2 Prod p_4 alpha_3 Prod gamma alpha_3 alpha_15 alpha_1 Prod gamma alpha_5 alpha_17 alpha_22 Prod gamma alpha_5 alpha_20 alpha_13 Prod c^(*) i_0 alpha_20 (p_3)_v Prod c i_4 alpha_13 (p_6)_v Prod ee i_1 alpha_22 (p_1)_u Prod ee^(*) i_3 alpha_17 (p_4)_u Prod mu i_5 alpha_1 (p_2)_u mu^(*) i_2 alpha_15 (p_5)_u Prod -1 Prod p_5 alpha_9 Prod gamma alpha_9 alpha_24 alpha_12 Prod gamma alpha_3 alpha_0 alpha_24 Prod gamma alpha_3 alpha_23 alpha_4 Prod gamma alpha_5 alpha_11 alpha_16 Prod gamma alpha_5 alpha_12 alpha_19 Prod c^(*) i_0 alpha_11 (p_3)_v Prod c i_4 alpha_16 (p_6)_v Prod ee i_1 alpha_19 (p_1)_u Prod ee^(*) i_3 alpha_0 (p_4)_u Prod mu i_5 alpha_4 (p_2)_u mu^(*) i_2 alpha_23 (p_5)_u [END]'\n",
            " b'[START] Prod 1/27 Prod i Prod Pow e 3 Prod Pow Sum Pow m_u 2 Sum s_13 Prod -1 s_14 Prod -1 s_34 Prod 1/2 reg_prop -1 Prod Pow Sum s_34 Prod -1/2 reg_prop -1 Sum Prod p_3 alpha_7 Prod gamma alpha_11 alpha_12 alpha_5 Prod gamma alpha_3 alpha_2 alpha_4 Prod gamma alpha_3 alpha_6 alpha_10 Prod gamma alpha_7 alpha_10 alpha_12 Prod A i_0 alpha_11 (p_3) Prod b^(*) i_4 alpha_2 (p_2)_v Prod b i_2 alpha_4 (p_5)_v Prod u^(*) i_1 alpha_6 (p_1)_v u i_3 alpha_5 (p_4)_v Prod -2 Prod p_4 alpha_11 Prod gamma alpha_3 alpha_8 alpha_1 Prod gamma alpha_3 alpha_0 alpha_9 Prod A i_0 alpha_11 (p_3) Prod b^(*) i_4 alpha_8 (p_2)_v Prod b i_2 alpha_1 (p_5)_v Prod u^(*) i_1 alpha_0 (p_1)_v u i_3 alpha_9 (p_4)_v [END]'], shape=(2,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for example_input_batch, example_target_batch in dataset.take(1):\n",
        "    print(example_input_batch[:2])\n",
        "    print()\n",
        "    print(example_input_batch[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9iewR3IdAKbC"
      },
      "outputs": [],
      "source": [
        "vocab_size = 500\n",
        "sequence_length = 250\n",
        "input_vectorize_layer = TextVectorization(\n",
        "    standardize=None,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length,\n",
        "    split='whitespace',\n",
        ")\n",
        "\n",
        "output_vectorize_layer = TextVectorization(\n",
        "    standardize=None,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length,\n",
        "    split='whitespace',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QhdnUsCsAKbC"
      },
      "outputs": [],
      "source": [
        "input_vectorize_layer.adapt(X_train_text)\n",
        "output_vectorize_layer.adapt(y_train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeQgJzpAAKbC",
        "outputId": "652f7fb3-4e52-4637-bfef-94954dc84bcb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 20), dtype=int64, numpy=\n",
              "array([[ 53,   2, 122,   2,  51,   2,   6,  52,  76,   2,   6,   4,   6,\n",
              "         92,   7,   4,   2,   5,  79,   2],\n",
              "       [ 53,   2, 110,   2,  51,   2,   6,  52, 105,   2,   6,   4,   6,\n",
              "         94,   7,   4,  88,   2,   5,  49],\n",
              "       [ 53,   2, 122,   2,  51,   2,   6,  52,  76,   2,   6,   4,   6,\n",
              "         91,   7,   4,   2,   5,  49,   2]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "example_tokens = input_vectorize_layer(example_input_batch)\n",
        "example_tokens[:3, :20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jC7wr5tXAKbC"
      },
      "outputs": [],
      "source": [
        "input_vocab = np.array(input_vectorize_layer.get_vocabulary())\n",
        "output_vocab = np.array(output_vectorize_layer.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGq3WCOSAKbC",
        "outputId": "50c2d54d-bfcd-4d8a-c0fd-c5ba2500b2e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['[START]', 'Prod', '1/12', 'Prod', 'i', 'Prod', 'Pow', 'e', '4',\n",
              "       'Prod', 'Pow', 'Sum', 'Pow', 'm_mu', '2', 'Sum', 'Prod', '-1',\n",
              "       's_25', 'Prod', '1/2', 'reg_prop', '-1', 'Prod', 'Pow', 'Sum',\n",
              "       'Pow', 'm_mu', '2', 'Sum', 'Prod', '-1', 's_24', 'Prod', '-1',\n",
              "       's_25', 's_45', 'Prod', '1/2', 'reg_prop', '-1', 'Prod', 'Pow',\n",
              "       'Sum', 'Pow', 'm_e', '2', 'Sum', 'Pow', 'm_mu', '2', 's_12',\n",
              "       'Prod', '-1', 's_14', 'Prod', '-1', 's_15', 'Prod', '-1', 's_24',\n",
              "       'Prod', '-1', 's_25', 's_45', 'Prod', '1/2', 'reg_prop', '-1',\n",
              "       'Sum', 'Prod', 'p_2', 'alpha_9', 'Prod', 'gamma', 'alpha_9',\n",
              "       'alpha_7', 'alpha_21', 'Prod', 'gamma', 'alpha_3', 'alpha_18',\n",
              "       'alpha_7', 'Prod', 'gamma', 'alpha_3', 'alpha_10', 'alpha_14',\n",
              "       'Prod', 'gamma', 'alpha_5', 'alpha_6', 'alpha_2', 'Prod', 'gamma',\n",
              "       'alpha_5', 'alpha_21', 'alpha_8', 'Prod', 'c^(*)', 'i_0',\n",
              "       'alpha_6', '(p_3)_v', 'Prod', 'c', 'i_4', 'alpha_2', '(p_6)_v',\n",
              "       'Prod', 'ee', 'i_1', 'alpha_8', '(p_1)_u', 'Prod', 'ee^(*)', 'i_3',\n",
              "       'alpha_18', '(p_4)_u', 'Prod', 'mu', 'i_5', 'alpha_14', '(p_2)_u',\n",
              "       'mu^(*)', 'i_2', 'alpha_10', '(p_5)_u', 'Sum', 'Prod', '-2',\n",
              "       'Prod', 'p_4', 'alpha_3', 'Prod', 'gamma', 'alpha_3', 'alpha_15',\n",
              "       'alpha_1', 'Prod', 'gamma', 'alpha_5', 'alpha_17', 'alpha_22',\n",
              "       'Prod', 'gamma', 'alpha_5', 'alpha_20', 'alpha_13', 'Prod',\n",
              "       'c^(*)', 'i_0', 'alpha_20', '(p_3)_v', 'Prod', 'c', 'i_4',\n",
              "       'alpha_13', '(p_6)_v', 'Prod', 'ee', 'i_1', 'alpha_22', '(p_1)_u',\n",
              "       'Prod', 'ee^(*)', 'i_3', 'alpha_17', '(p_4)_u', 'Prod', 'mu',\n",
              "       'i_5', 'alpha_1', '(p_2)_u', 'mu^(*)', 'i_2', 'alpha_15',\n",
              "       '(p_5)_u', 'Prod', '-1', 'Prod', 'p_5', 'alpha_9', 'Prod', 'gamma',\n",
              "       'alpha_9', 'alpha_24', 'alpha_12', 'Prod', 'gamma', 'alpha_3',\n",
              "       'alpha_0', 'alpha_24', 'Prod', 'gamma', 'alpha_3', 'alpha_23',\n",
              "       'alpha_4', 'Prod', 'gamma', 'alpha_5', 'alpha_11', 'alpha_16',\n",
              "       'Prod', 'gamma', 'alpha_5', 'alpha_12', 'alpha_19', 'Prod',\n",
              "       'c^(*)', 'i_0', 'alpha_11', '(p_3)_v', 'Prod', 'c', 'i_4',\n",
              "       'alpha_16', '(p_6)_v', 'Prod', 'ee', 'i_1', 'alpha_19', '(p_1)_u',\n",
              "       'Prod', 'ee^(*)', 'i_3', 'alpha_0', '(p_4)_u', 'Prod', 'mu', 'i_5',\n",
              "       'alpha_4', '(p_2)_u', 'mu^(*)', 'i_2', 'alpha_23', '(p_5)_u',\n",
              "       '[END]', '', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
              "      dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "input_vocab[example_tokens[0].numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HS_sPN8AKbD",
        "outputId": "885eec47-fb14-43b8-a76d-d547489c8dc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(250,), dtype=int64, numpy=\n",
              "array([ 53,   2, 122,   2,  51,   2,   6,  52,  76,   2,   6,   4,   6,\n",
              "        92,   7,   4,   2,   5,  79,   2,   8,  14,   5,   2,   6,   4,\n",
              "         6,  92,   7,   4,   2,   5,  77,   2,   5,  79,  81,   2,   8,\n",
              "        14,   5,   2,   6,   4,   6,  91,   7,   4,   6,  92,   7,  55,\n",
              "         2,   5,  49,   2,   5,  82,   2,   5,  77,   2,   5,  79,  81,\n",
              "         2,   8,  14,   5,   4,   2,  85,  20,   2,   3,  20,  16,  41,\n",
              "         2,   3,  28,  34,  16,   2,   3,  28,  22,  29,   2,   3,  27,\n",
              "        21,  26,   2,   3,  27,  41,  17,   2,  66,  11,  21,  43,   2,\n",
              "        67,  13,  26,  44,   2,  65,  10,  17,  38,   2,  64,  12,  34,\n",
              "        42,   2,  59,  15,  29,  46,  58,   9,  22,  48,   4,   2,  95,\n",
              "         2,  84,  28,   2,   3,  28,  31,  25,   2,   3,  27,  33,  40,\n",
              "         2,   3,  27,  37,  32,   2,  66,  11,  37,  43,   2,  67,  13,\n",
              "        32,  44,   2,  65,  10,  40,  38,   2,  64,  12,  33,  42,   2,\n",
              "        59,  15,  25,  46,  58,   9,  31,  48,   2,   5,   2,  90,  20,\n",
              "         2,   3,  20,  35,  24,   2,   3,  28,  19,  35,   2,   3,  28,\n",
              "        39,  18,   2,   3,  27,  23,  30,   2,   3,  27,  24,  36,   2,\n",
              "        66,  11,  23,  43,   2,  67,  13,  30,  44,   2,  65,  10,  36,\n",
              "        38,   2,  64,  12,  19,  42,   2,  59,  15,  18,  46,  58,   9,\n",
              "        39,  48,  54,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0])>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "example_tokens[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "jmSrJFc-AKbD",
        "outputId": "dd2dea7e-2cb1-441b-b327-8b6a7b3dd8fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens)\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDVo0hWDAKbD"
      },
      "source": [
        "# The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0LFgftTRAKbD"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 128\n",
        "units = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "iffRyJrNAKbD"
      },
      "outputs": [],
      "source": [
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5tjW-AGnAKbD"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   # Return the sequence and state\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(tokens, ('batch', 's'))\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding for each token.\n",
        "    vectors = self.embedding(tokens)\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "\n",
        "    # 3. The GRU processes the embedding sequence.\n",
        "    #    output shape: (batch, s, enc_units)\n",
        "    #    state shape: (batch, enc_units)\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(state, ('batch', 'enc_units'))\n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    return output, state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXFC0L6EAKbE",
        "outputId": "f9fde4a6-9545-45f7-b74d-0a316a652356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch, shape (batch): (64,)\n",
            "Input batch tokens, shape (batch, s): (64, 250)\n",
            "Encoder output, shape (batch, s, units): (64, 250, 256)\n",
            "Encoder state, shape (batch, units): (64, 256)\n"
          ]
        }
      ],
      "source": [
        "# Convert the input text to tokens.\n",
        "example_tokens = input_vectorize_layer(example_input_batch)\n",
        "\n",
        "# Encode the input sequence.\n",
        "encoder = Encoder(len(input_vectorize_layer.get_vocabulary()),\n",
        "                  embedding_dim, units)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n",
        "\n",
        "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
        "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
        "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmLVg7wrAKbE"
      },
      "source": [
        "## Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ucCUJ4TgAKbE"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jV2T_nQlAKbE"
      },
      "outputs": [],
      "source": [
        "attention_layer = BahdanauAttention(units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLnBBZsNAKbE",
        "outputId": "56e16b5f-ed23-49db-bdbd-1a750f387c0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 250])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "(example_tokens != 0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zJcKAQHHAKbF"
      },
      "outputs": [],
      "source": [
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "gwR4yZojAKbF"
      },
      "outputs": [],
      "source": [
        "context_vector, attention_weights = attention_layer(\n",
        "    query=example_attention_query,\n",
        "    value=example_enc_output,\n",
        "    mask=(example_tokens != 0)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEyl1VTCAKbF",
        "outputId": "9cf93a40-2c71-48e1-f989-dc12d5561d05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch_size, query_seq_length, units):           (64, 2, 256)\n",
            "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (64, 2, 250)\n"
          ]
        }
      ],
      "source": [
        "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
        "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "7EnPzLsEAKbF",
        "outputId": "31680a67-2211-4b84-e0cc-0e4c0e95e2cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr4nbbayAKbF"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "e2BdILLWAKbF"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    # For Step 1. The embedding layer convets token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # For step 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "    # For step 5. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "rqA7qvp5AKbF"
      },
      "outputs": [],
      "source": [
        "import typing\n",
        "from typing import Any, Tuple\n",
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "H-b6S1SyAKbF"
      },
      "outputs": [],
      "source": [
        "def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(inputs.new_tokens, ('batch', 't'))\n",
        "  shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
        "  shape_checker(inputs.mask, ('batch', 's'))\n",
        "\n",
        "  if state is not None:\n",
        "    shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 1. Lookup the embeddings\n",
        "  vectors = self.embedding(inputs.new_tokens)\n",
        "  shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
        "\n",
        "  # Step 2. Process one step with the RNN\n",
        "  rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "  shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 3. Use the RNN output as the query for the attention over the\n",
        "  # encoder output.\n",
        "  context_vector, attention_weights = self.attention(\n",
        "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "  shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "  # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "  #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "  # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "  attention_vector = self.Wc(context_and_rnn_output)\n",
        "  shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
        "\n",
        "  # Step 5. Generate logit predictions:\n",
        "  logits = self.fc(attention_vector)\n",
        "  shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
        "\n",
        "  return DecoderOutput(logits, attention_weights), state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "hmXThkohAKbG"
      },
      "outputs": [],
      "source": [
        "Decoder.call = call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "aH0avH3rAKbG"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(len(output_vectorize_layer.get_vocabulary()),\n",
        "    embedding_dim, units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sSTGbu0RAKbG"
      },
      "outputs": [],
      "source": [
        "example_output_tokens = output_vectorize_layer(example_target_batch)\n",
        "\n",
        "start_index = output_vectorize_layer.get_vocabulary().index('[START]')\n",
        "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZwvocHJAKbG",
        "outputId": "e63f12fa-87e0-45ad-e241-d21ebb5628ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits shape: (batch_size, t, output_vocab_size) (64, 1, 165)\n",
            "state shape: (batch_size, dec_units) (64, 256)\n"
          ]
        }
      ],
      "source": [
        "# Run the decoder\n",
        "dec_result, dec_state = decoder(\n",
        "    inputs = DecoderInput(new_tokens=first_token,\n",
        "                          enc_output=example_enc_output,\n",
        "                          mask=(example_tokens != 0)),\n",
        "    state = example_enc_state\n",
        ")\n",
        "\n",
        "print(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\n",
        "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWBLB8QaAKbH",
        "outputId": "64a6eb20-2714-4cba-f547-6e855765e4e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['1/648'],\n",
              "       ['d^(*)'],\n",
              "       ['A'],\n",
              "       ['4/9'],\n",
              "       ['(p_2)']], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
        "vocab = np.array(output_vectorize_layer.get_vocabulary())\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "jhvMKIyrAKbH"
      },
      "outputs": [],
      "source": [
        "dec_result, dec_state = decoder(\n",
        "    DecoderInput(sampled_token,\n",
        "                 example_enc_output,\n",
        "                 mask=(example_tokens != 0)),\n",
        "    state=dec_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yezC3CXfAKbH",
        "outputId": "558d47bf-a178-43e1-ae8c-803ccb26be14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['s_25'],\n",
              "       ['alpha_3'],\n",
              "       ['-1/4'],\n",
              "       ['(p_2)_u'],\n",
              "       ['i_2']], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq5xaP7eAKbH"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "dXaO42s_AKbH"
      },
      "outputs": [],
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(y_true, ('batch', 't'))\n",
        "    shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "b4fPlDY2AKbH"
      },
      "outputs": [],
      "source": [
        "class TrainTranslator(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor, \n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(len(input_vectorize_layer.get_vocabulary()),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(len(output_vectorize_layer.get_vocabulary()),\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_vectorize_layer\n",
        "    self.output_text_processor = output_vectorize_layer\n",
        "    self.use_tf_function = use_tf_function\n",
        "    self.shape_checker = ShapeChecker()\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    self.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "TKk2bc3fAKbI"
      },
      "outputs": [],
      "source": [
        "def _preprocess(self, input_text, target_text):\n",
        "  self.shape_checker(input_text, ('batch',))\n",
        "  self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "  # Convert the text to token IDs\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  target_tokens = self.output_text_processor(target_text)\n",
        "  self.shape_checker(input_tokens, ('batch', 's'))\n",
        "  self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "  # Convert IDs to masks.\n",
        "  input_mask = input_tokens != 0\n",
        "  self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "  target_mask = target_tokens != 0\n",
        "  self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "  return input_tokens, input_mask, target_tokens, target_mask\n",
        "TrainTranslator._preprocess = _preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "F_eq8wf4AKbI"
      },
      "outputs": [],
      "source": [
        "def _train_step(self, inputs):\n",
        "  input_text, target_text = inputs  \n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "  max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    # Initialize the decoder's state to the encoder's final state.\n",
        "    # This only works if the encoder and decoder have the same number of\n",
        "    # units.\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      # Pass in two tokens from the target sequence:\n",
        "      # 1. The current input to the decoder.\n",
        "      # 2. The target for the decoder's next prediction.\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "\n",
        "    # Average the loss over all non padding tokens.\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "  # Apply an optimization step\n",
        "  variables = self.trainable_variables \n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Return a dict mapping metric names to current value\n",
        "  return {'batch_loss': average_loss}\n",
        "TrainTranslator._train_step = _train_step\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "rEgX2QkNAKbI"
      },
      "outputs": [],
      "source": [
        "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "  # Run the decoder one step.\n",
        "  decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "\n",
        "  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "  self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "  self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "  self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "  # `self.loss` returns the total for non-padded tokens\n",
        "  y = target_token\n",
        "  y_pred = dec_result.logits\n",
        "  step_loss = self.loss(y, y_pred)\n",
        "\n",
        "  return step_loss, dec_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "It0kszK_AKbI"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._loop_step = _loop_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "-hIVdf38AKbI"
      },
      "outputs": [],
      "source": [
        "translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_vectorize_layer,\n",
        "    output_text_processor=output_vectorize_layer,\n",
        "    use_tf_function=False)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uYdOBGyAKbJ",
        "outputId": "b0dc87ac-90bb-40cc-8f60-7b015609cf57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.105945473900581"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "np.log(len(output_vectorize_layer.get_vocabulary()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "FAH7CCg8AKbJ"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# for n in range(20):\n",
        "#   print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "# print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "EYsWuGm2AKbJ"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def _tf_train_step(self, inputs):\n",
        "  return self._train_step(inputs)\n",
        "\n",
        "TrainTranslator._tf_train_step = _tf_train_step\n",
        "translator.use_tf_function = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzpgzqJ0AKbJ",
        "outputId": "66a0fe5c-d882-402c-c462-e80d23ed7447"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.083062>}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "translator.train_step([example_input_batch, example_target_batch])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9pArakYAKbJ",
        "outputId": "56730d15-d738-42df-bc08-b1a3ec87385d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.058987>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.029543>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.985088>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.9142094>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.8004684>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.619523>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.3588667>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.56096>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.235846>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.18982>}\n",
            "\n",
            "CPU times: user 1min 6s, sys: 14.8 s, total: 1min 21s\n",
            "Wall time: 24.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "WjdcaFJODUud",
        "outputId": "d5d47a75-ed6a-47bd-bd70-d1b28fe8c937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "......."
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-4be090e1c8d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_input_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_target_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-547e98dd6c31>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_checker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShapeChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tf_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "losses = []\n",
        "for n in range(50):\n",
        "  print('.', end='')\n",
        "  logs = translator.train_step([example_input_batch, example_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUizXGPrDZLm"
      },
      "source": [
        "## Full Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "eh3qLooiDVKb"
      },
      "outputs": [],
      "source": [
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_vectorize_layer,\n",
        "    output_text_processor=output_vectorize_layer)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "5053YM4CDj6m"
      },
      "outputs": [],
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "KCzRqAsFDlVe",
        "outputId": "9da429ae-8773-4ce5-a380-4d08e80813f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-25e5d3057f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_translator.fit(dataset, epochs=20,\n\u001b[0;32m----> 2\u001b[0;31m                      callbacks=[batch_loss])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    961\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    784\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    785\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 786\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2981\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2983\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2984\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m                 ))\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[1;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-547e98dd6c31>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_checker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShapeChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tf_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m-> 2955\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3829\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3830\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3831\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3832\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m                 ))\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filehxq4a16m.py\u001b[0m in \u001b[0;36mtf___tf_train_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0m_attach_error_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_fileeft5tr06.py\u001b[0m in \u001b[0;36mtf___train_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0maverage_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_WhileGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    385\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_none_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m       \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_grad_fn_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m       stateful_parallelism)\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbody_grad_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhile_op_needs_rewrite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[0;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations, stateful_parallelism)\u001b[0m\n\u001b[1;32m    691\u001b[0m                                          \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhile_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                                          body_graph_inputs, body_graph_outputs),\n\u001b[0;32m--> 693\u001b[0;31m       acd_record_initial_resource_uses=stateful_parallelism)\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m   \u001b[0;31m# Update the list of outputs with tensors corresponding to the captured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    686\u001b[0m   grad_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[1;32m    687\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m       \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m       func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[0;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[1;32m    744\u001b[0m   grad_outs = gradients_util._GradientsHelper(\n\u001b[1;32m    745\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m       unconnected_gradients=\"zero\")\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m   \u001b[0;31m# TODO(b/118712257): Handle the case when grad_outs has None's e.g. when there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 680\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    681\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 680\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    681\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_rewrite_forward_and_call_backward\u001b[0;34m(self, op, *doutputs)\u001b[0m\n\u001b[1;32m    666\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rewrite_forward_and_call_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;34m\"\"\"Add outputs to the forward call and feed them to the grad function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m     \u001b[0mforward_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackwards_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mbackwards_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    647\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m           \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m           func_graph=backwards_graph)\n\u001b[0m\u001b[1;32m    650\u001b[0m       \u001b[0mbackwards_graph_captures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackwards_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_captures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m       captures_from_forward = [\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[0;34m(*grad_ys)\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             src_graph=self._func_graph)\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 680\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    681\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m   \u001b[0;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 680\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    681\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_WhileGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m    385\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_none_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m       \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_grad_fn_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m       stateful_parallelism)\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbody_grad_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhile_op_needs_rewrite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[0;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations, stateful_parallelism)\u001b[0m\n\u001b[1;32m    691\u001b[0m                                          \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhile_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                                          body_graph_inputs, body_graph_outputs),\n\u001b[0;32m--> 693\u001b[0;31m       acd_record_initial_resource_uses=stateful_parallelism)\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m   \u001b[0;31m# Update the list of outputs with tensors corresponding to the captured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    686\u001b[0m   grad_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[1;32m    687\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m       \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m       func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[0;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[1;32m    744\u001b[0m   grad_outs = gradients_util._GradientsHelper(\n\u001b[1;32m    745\u001b[0m       \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m       unconnected_gradients=\"zero\")\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m   \u001b[0;31m# TODO(b/118712257): Handle the case when grad_outs has None's e.g. when there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    579\u001b[0m           \u001b[0mloop_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnterGradWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         out_grads = _AggregatedGrads(grads, op, gradient_uid, loop_state,\n\u001b[0;32m--> 581\u001b[0;31m                                      aggregation_method)\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloop_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m           \u001b[0mloop_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExitGradWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_AggregatedGrads\u001b[0;34m(grads, op, gradient_uid, loop_state, aggregation_method)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m           \u001b[0mused\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"add_n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m           \u001b[0mout_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MultiDeviceAddN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_uid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m         logging.vlog(2, \"  _AggregatedGrads %d x %s using %s\", len(out_grad),\n\u001b[1;32m   1000\u001b[0m                      tensor_shape, used)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MultiDeviceAddN\u001b[0;34m(tensor_list, gradient_uid)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mgradient_uid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m         ignore_existing=True):\n\u001b[0m\u001b[1;32m    883\u001b[0m       \u001b[0msummands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_colocate_with_for_gradient\u001b[0;34m(self, op, gradient_uid, ignore_existing)\u001b[0m\n\u001b[1;32m   4587\u001b[0m   def _colocate_with_for_gradient(self, op, gradient_uid,\n\u001b[1;32m   4588\u001b[0m                                   ignore_existing=False):\n\u001b[0;32m-> 4589\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4590\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgradient_uid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4591\u001b[0m         \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_enclosing_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcolocate_with\u001b[0;34m(self, op, ignore_existing)\u001b[0m\n\u001b[1;32m   4662\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdevice_only_candidate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4663\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_only_candidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4664\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4665\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4666\u001b[0m       raise ValueError(\"Trying to reset colocation (op is None) but \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/traceable_stack.py\u001b[0m in \u001b[0;36mpush_obj\u001b[0;34m(self, obj, offset)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Offset is defined in \"Args\" as relative to the caller.  We are 1 frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# beyond the caller and need to compensate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtraceable_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_filename_and_line_from_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpop_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/traceable_stack.py\u001b[0m in \u001b[0;36mset_filename_and_line_from_caller\u001b[0;34m(self, offset)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \"\"\"\n\u001b[1;32m     50\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUCCESS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Offset is defined in \"Args\" as relative to the caller. We are one frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# beyond the caller.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_translator.fit(dataset, epochs=20,\n",
        "                     callbacks=[batch_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfQT56gYEAmI"
      },
      "outputs": [],
      "source": [
        "plt.plot(batch_loss.logs)\n",
        "plt.ylim([0, 3])\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/token')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DDmoZ0cEB9R"
      },
      "source": [
        "## Translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "StFGBq4OEHv1"
      },
      "outputs": [],
      "source": [
        "class Translator(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, input_text_processor,\n",
        "               output_text_processor):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "\n",
        "    self.output_token_string_from_index = (\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "\n",
        "    # The output should never generate padding, unknown, or start.\n",
        "    index_from_string = tf.keras.layers.StringLookup(\n",
        "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = index_from_string(tf.constant('[START]'))\n",
        "    self.end_token = index_from_string(tf.constant('[END]'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUuqv1FXEbB7",
        "outputId": "04e82be7-b485-4e3f-d8c9-9cef744aac83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "translator = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    input_text_processor=input_vectorize_layer,\n",
        "    output_text_processor=output_vectorize_layer,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Vj8hO4x2Eqgu"
      },
      "outputs": [],
      "source": [
        "def tokens_to_text(self, result_tokens):\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(result_tokens, ('batch', 't'))\n",
        "  result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "  shape_checker(result_text_tokens, ('batch', 't'))\n",
        "\n",
        "  result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ')\n",
        "  shape_checker(result_text, ('batch'))\n",
        "\n",
        "  result_text = tf.strings.strip(result_text)\n",
        "  shape_checker(result_text, ('batch',))\n",
        "  return result_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "EzGCLgTNEtc_"
      },
      "outputs": [],
      "source": [
        "Translator.tokens_to_text = tokens_to_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0I2Xx-6Eu4a",
        "outputId": "73460c86-59c6-4126-fc93-577a35695ec6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'-1/48 b^(*)', b'2/9 alpha_5', b'd (p_4)_u', b'1/2 s_14',\n",
              "       b'mu (p_1)_u'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "example_output_tokens = tf.random.uniform(\n",
        "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
        "    maxval=len(output_vectorize_layer.get_vocabulary()))\n",
        "translator.tokens_to_text(example_output_tokens).numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "DbDEi_i0EwJN"
      },
      "outputs": [],
      "source": [
        "def sample(self, logits, temperature):\n",
        "  shape_checker = ShapeChecker()\n",
        "  # 't' is usually 1 here.\n",
        "  shape_checker(logits, ('batch', 't', 'vocab'))\n",
        "  shape_checker(self.token_mask, ('vocab',))\n",
        "\n",
        "  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "  shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
        "\n",
        "  # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "  logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "  if temperature == 0.0:\n",
        "    new_tokens = tf.argmax(logits, axis=-1)\n",
        "  else: \n",
        "    logits = tf.squeeze(logits, axis=1)\n",
        "    new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                        num_samples=1)\n",
        "\n",
        "  shape_checker(new_tokens, ('batch', 't'))\n",
        "\n",
        "  return new_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "JjvnQ0VmE2_k"
      },
      "outputs": [],
      "source": [
        "Translator.sample = sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE7W-OjlE4ib",
        "outputId": "5fd58d51-226b-4bcf-b70c-3d113a6ff4aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
              "array([[ 21],\n",
              "       [ 30],\n",
              "       [ 30],\n",
              "       [ 23],\n",
              "       [159]])>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "example_logits = tf.random.normal([5, 1, len(output_vectorize_layer.get_vocabulary())])\n",
        "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
        "example_output_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "_O8GnIwIE5p9"
      },
      "outputs": [],
      "source": [
        "def translate_unrolled(self,\n",
        "                       input_text, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  batch_size = tf.shape(input_text)[0]\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "  result_tokens = []\n",
        "  attention = []\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                             enc_output=enc_output,\n",
        "                             mask=(input_tokens!=0))\n",
        "\n",
        "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "    attention.append(dec_result.attention_weights)\n",
        "\n",
        "    new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "    # Collect the generated tokens\n",
        "    result_tokens.append(new_tokens)\n",
        "\n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Convert the list of generates token ids to a list of strings.\n",
        "  result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "  result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = tf.concat(attention, axis=1)\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "RbgbGhuwFEj2"
      },
      "outputs": [],
      "source": [
        "Translator.translate = translate_unrolled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYG0tJ7jFGOW",
        "outputId": "b0f97219-2aa6-428a-e51e-897b4778d5aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i_1 t^(*) reg_prop i_2 alpha_3 1/4 A^(*) t^(*) alpha_10 -1/8 1/16 1/9 u (p_4)_u i_5 3 alpha_2 s_45 s_23 p_1 i_2 -1/162 4 (p_3)_u s_15 -1/48 -1/72 c -1/108 4/27 m_t i_2 -4/27 d^(*) (p_4)_v (p_6)_u Pow s_12 3 1/216 -1/108 (p_5)_u s_23 1/24 (p_3) 1/72 ee (p_4)_v 1/108 3\n",
            "m_c (p_2) 2/27 1/6 s_12 tt^(*) -1/6 alpha_14 -1/36 s i_5 Pow alpha_23 alpha_12 Pow 1/16 4/9 alpha_14 (p_3)_u alpha_24 gamma -1/81 c^(*) -1/4 -1/4 alpha_24 p_2 1/324 1/3 s_23 4/9 p_4 1/81 (p_2) alpha_2 p_5 alpha_1 i -2/9 1/2 m_mu (p_4)_u (p_4)_v 1/6 -2/27 2/81 1/1296 -2/81 s p_2\n",
            "\n",
            "CPU times: user 1.41 s, sys: 0 ns, total: 1.41 s\n",
            "Wall time: 1.38 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "input_text = tf.constant([\n",
        "    'Prod -1/6 Prod i Prod Pow e 4 Prod Pow Sum Pow m_c 2 Sum s_23',\n",
        "    'Prod 1/324 Prod i Prod Pow e 4 Prod Pow Sum Pow m_s 2 Sum Prod -1'\n",
        "])\n",
        "\n",
        "result = translator.translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDkPn_g8FPhg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amvPbYAhFiEW"
      },
      "source": [
        "# Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "4E21oEeUFi3n"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "def tf_translate(self, input_text):\n",
        "  return self.translate(input_text)\n",
        "\n",
        "Translator.tf_translate = tf_translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js0Olkf8Fl25",
        "outputId": "dcfce48e-95c2-44a4-bfce-394778c7a07b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 22.9 s, sys: 78.5 ms, total: 22.9 s\n",
            "Wall time: 22.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)\n",
        "# first time takes long because of compiling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwlGiz0PFn1M",
        "outputId": "29152b1f-08bd-4602-bcbb-9de10d1d8f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ee s -1/16 b 2/9 -1/6 (p_4)_u ee^(*) 1/162 (p_2)\n",
            "1/1296 m_tt -1/648 alpha_5 -1/108 m_e 1/36 (p_3)_v 1/1296 alpha_21 1/48 alpha_2 3 ee^(*) m_c alpha_1 (p_4)_u -1/3 -8/27 (p_1)_v i_4 1/324 alpha_5 2/27 alpha_17 s^(*) m_mu 1/108 tt^(*) alpha_11 (p_2)_v m_tt\n",
            "\n",
            "CPU times: user 143 ms, sys: 14.1 ms, total: 157 ms\n",
            "Wall time: 83.1 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKKPfNvlF1V-"
      },
      "source": [
        "## Use Symbolic Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "jUEz6eYBF1E6"
      },
      "outputs": [],
      "source": [
        "def translate_symbolic(self,\n",
        "                       input_text,\n",
        "                       *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(input_text, ('batch',))\n",
        "\n",
        "  batch_size = tf.shape(input_text)[0]\n",
        "\n",
        "  # Encode the input\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  shape_checker(input_tokens, ('batch', 's'))\n",
        "\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "  shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "  shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "  # Initialize the decoder\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  shape_checker(new_tokens, ('batch', 't1'))\n",
        "\n",
        "  # Initialize the accumulators\n",
        "  result_tokens = tf.TensorArray(tf.int64, size=1, dynamic_size=True)\n",
        "  attention = tf.TensorArray(tf.float32, size=1, dynamic_size=True)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  shape_checker(done, ('batch', 't1'))\n",
        "\n",
        "  for t in tf.range(max_length):\n",
        "    dec_input = DecoderInput(\n",
        "        new_tokens=new_tokens, enc_output=enc_output, mask=(input_tokens != 0))\n",
        "\n",
        "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "    shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "    attention = attention.write(t, dec_result.attention_weights)\n",
        "\n",
        "    new_tokens = self.sample(dec_result.logits, temperature)\n",
        "    shape_checker(dec_result.logits, ('batch', 't1', 'vocab'))\n",
        "    shape_checker(new_tokens, ('batch', 't1'))\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "    # Collect the generated tokens\n",
        "    result_tokens = result_tokens.write(t, new_tokens)\n",
        "\n",
        "    if tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Convert the list of generated token ids to a list of strings.\n",
        "  result_tokens = result_tokens.stack()\n",
        "  shape_checker(result_tokens, ('t', 'batch', 't0'))\n",
        "  result_tokens = tf.squeeze(result_tokens, -1)\n",
        "  result_tokens = tf.transpose(result_tokens, [1, 0])\n",
        "  shape_checker(result_tokens, ('batch', 't'))\n",
        "\n",
        "  result_text = self.tokens_to_text(result_tokens)\n",
        "  shape_checker(result_text, ('batch',))\n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = attention.stack()\n",
        "    shape_checker(attention_stack, ('t', 'batch', 't1', 's'))\n",
        "\n",
        "    attention_stack = tf.squeeze(attention_stack, 2)\n",
        "    shape_checker(attention_stack, ('t', 'batch', 's'))\n",
        "\n",
        "    attention_stack = tf.transpose(attention_stack, [1, 0, 2])\n",
        "    shape_checker(attention_stack, ('batch', 't', 's'))\n",
        "\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "7KDn947tFwA5"
      },
      "outputs": [],
      "source": [
        "Translator.translate = translate_symbolic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzoYO8WFFzB9",
        "outputId": "9e009aa9-a35e-4a04-deaf-03253323623d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha_17 i p_3 1/27 1/18 alpha_13 alpha_7 alpha_3 -1/2 s_13 u^(*) 1/24 1/216 1/324 -1/162 Pow (p_4) (p_1) -1/24 e alpha_1 d^(*) alpha_6 i_1 -1/216 m_e ee^(*) mu^(*) -1/18 1/4 alpha_1 p_4 1/3 2/3 gamma t 1/54 -1/18 alpha_23 alpha_0 p_3 i_5 -1/54 alpha_22 m_mu alpha_10 -1/6 alpha_21 (p_1)_v -4/9\n",
            "i_2 s m_d -1/18 alpha_10 s_45 -1/72 s_13 1/6 m_u -4/27 s_15 alpha_20 i -1/216 -1/324 (p_5) alpha_18 4 (p_1)_v i_1 reg_prop -1/81 i alpha_5 p_5 1/1296 alpha_10 4/27 s_24 m_mu 3 (p_3)_v s_12 4 -1/648 (p_5)_v -1 m_mu p_1 t e ee^(*) tt^(*) mu t 1/3 -1/2 u^(*) 3\n",
            "\n",
            "CPU times: user 1.48 s, sys: 10.8 ms, total: 1.49 s\n",
            "Wall time: 1.46 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = translator.translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "E47Z4ZT_F5vS"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "def tf_translate(self, input_text):\n",
        "  return self.translate(input_text)\n",
        "\n",
        "Translator.tf_translate = tf_translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41AbwDg-GDLz",
        "outputId": "538d05ec-d335-4634-ef67-5bcf29a567c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.28 s, sys: 31.5 ms, total: 2.31 s\n",
            "Wall time: 2.13 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlBDgpvRGEuR",
        "outputId": "e5d1c6d1-df82-4ab4-dfcc-c7fd913d762a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tt^(*) i_2 alpha_22 2/81 s_45 p_2 alpha_8 8/27 alpha_24 m_tt -1/16 -1/216 s_14 m_tt -2/27 2 (p_2)_u -1/24 b alpha_12 m_e (p_2)_u\n",
            "1/324 1/48 tt^(*) -8/27 (p_2)_v -1/27 u 1/12 -1/12 (p_3)_u mu -1/18 (p_1)_v m_d mu^(*) alpha_15 m_mu 1/4 alpha_22 1/324 1/36 s_25 alpha_18 1/81 s_14 -1/24 A -2/27 i_4 m_d -1/48 alpha_14 s_45 (p_4)_u 4/27 1/16 -1/4 1/2 u^(*) alpha_18 i_2 1/72 -1/72 -1/36 i_5 mu^(*) s^(*) s alpha_9 1/54\n",
            "\n",
            "CPU times: user 222 ms, sys: 42.1 ms, total: 264 ms\n",
            "Wall time: 104 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = translator.tf_translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1d4SrMnGXan"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YybUTrzQGNly"
      },
      "outputs": [],
      "source": [
        "tf.saved_model.save(translator, 'models/2022-07-19-RNNAttention',\n",
        "                    signatures={'serving_default': translator.tf_translate})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "XSZvWCvrGc39"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.saved_model.load('models/2022-07-19-RNNAttention')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey_xNtmqGwII",
        "outputId": "a46fa784-c4c6-43ad-82e3-4587a12dbd49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ee -1/6 Prod i Prod Pow e 2 Prod Pow Sum s_13 Prod 1/2 reg_prop -1 Sum Prod p_1 s_35 Prod gamma s_35 alpha_21 alpha_2 Prod gamma alpha_14 alpha_21 alpha_2 Prod gamma alpha_1 alpha_21 alpha_3 Prod ee i_1 alpha_17 (p_1)_u Prod ee^(*) i_3 alpha_13 (p_6)_u Prod mu i_4 alpha_18 (p_2)_u\n",
            "Prod -1/2 Prod i Prod Pow e 2 Prod Pow Sum Pow m_s 2 Sum Prod -1 s_35 Prod 1/2 reg_prop -1 Prod Pow Sum Pow m_s 2 Sum s_13 Prod -1 s_13 Prod -1 s_34 Prod 1/2 reg_prop -1 Sum Prod p_1 alpha_14 Prod gamma alpha_14 alpha_4 alpha_4 Prod\n",
            "\n",
            "CPU times: user 497 ms, sys: 52.7 ms, total: 550 ms\n",
            "Wall time: 381 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = reloaded.tf_translate(input_text)\n",
        "\n",
        "for tr in result['text']:\n",
        "  print(tr.numpy().decode())\n",
        "\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "kt4ug6N6o21U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LJnB8WFEpPZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = reloaded.tf_translate(X_test_text)\n",
        "\n",
        "y_pred = []\n",
        "for tr in result['text']:\n",
        "  y_pred.append(tr.numpy().decode())"
      ],
      "metadata": {
        "id": "60la30Leo1tz"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qJDc96YtqUEv",
        "outputId": "285b8bd9-bf18-4b9e-9e8f-93fd0ce7e642"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Prod -1/54 Prod i Prod Pow e 4 Prod Pow Sum Pow m_mu 2 Sum Prod -1 s_14 Prod 1/2 reg_prop -1 Prod Pow Sum Pow m_s 2 Sum s_23 Prod 1/2 reg_prop -1 Prod Pow Sum Pow m_mu 2 Sum Prod -1 s_14 Prod -1 s_15 s_45 Prod 1/2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "Npx7W3HPpi9u",
        "outputId": "08b84883-dcb1-4543-8be5-41d37aa563fa"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] Prod -1/54 Prod i Prod Pow e 4 Prod Pow Sum Pow m_mu 2 Sum Prod -1 s_14 Prod 1/2 reg_prop -1 Prod Pow Sum Pow m_s 2 Sum s_23 Prod 1/2 reg_prop -1 Prod Pow Sum Pow m_mu 2 Sum Prod -1 s_14 Prod -1 s_15 s_45 Prod 1/2 reg_prop -1 Sum Prod p_1 alpha_14 Prod gamma alpha_1 alpha_16 alpha_4 Prod gamma alpha_1 alpha_2 alpha_5 Prod gamma alpha_0 alpha_19 alpha_21 Prod gamma alpha_0 alpha_23 alpha_3 Prod gamma alpha_14 alpha_4 alpha_23 Prod c^(*) i_2 alpha_16 (p_5)_u Prod c i_3 alpha_3 (p_6)_v Prod s i_5 alpha_21 (p_2)_u Prod s^(*) i_0 alpha_19 (p_3)_v Prod mu i_1 alpha_5 (p_1)_u mu^(*) i_4 alpha_2 (p_4)_u Sum Prod -1 Prod p_4 alpha_14 Prod gamma alpha_1 alpha_15 alpha_12 Prod gamma alpha_1 alpha_10 alpha_13 Prod gamma alpha_0 alpha_20 alpha_8 Prod gamma alpha_0 alpha_11 alpha_7 Prod gamma alpha_14 alpha_12 alpha_11 Prod c^(*) i_2 alpha_15 (p_5)_u Prod c i_3 alpha_7 (p_6)_v Prod s i_5 alpha_8 (p_2)_u Prod s^(*) i_0 alpha_20 (p_3)_v Prod mu i_1 alpha_13 (p_1)_u mu^(*) i_4 alpha_10 (p_4)_u Prod -2 Prod p_5 alpha_1 Prod gamma alpha_1 alpha_6 alpha_24 Prod gamma alpha_0 alpha_17 alpha_22 Prod gamma alpha_0 alpha_18 alpha_9 Prod c^(*) i_2 alpha_17 (p_5)_u Prod c i_3 alpha_22 (p_6)_v Prod s i_5 alpha_9 (p_2)_u Prod s^(*) i_0 alpha_18 (p_3)_v Prod mu i_1 alpha_24 (p_1)_u mu^(*) i_4 alpha_6 (p_4)_u [END]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def token_accuracy(y_true, y_pred, verbose=0):\n",
        "    \"\"\"\n",
        "    compare two arrays and check how many entries are the same at the same position\n",
        "    \"\"\"\n",
        "    max_ind = np.min([len(y_true), len(y_pred)])\n",
        "    correct_ctr = 0\n",
        "    # ignore [start] and [end]\n",
        "    max_correct = len(y_test)\n",
        "    for i in range(1, max_ind-1):\n",
        "        if verbose: ic([y_true[i], y_pred[i]])\n",
        "        if y_true[i] == y_pred[i]:\n",
        "            correct_ctr += 1\n",
        "    return correct_ctr / max_correct"
      ],
      "metadata": {
        "id": "hHZWshYCr_5D"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_test, y_pred):\n",
        "    y_pred_split = [y.split() for y in y_pred]\n",
        "    y_test_split = [y.split()[1:-1] for y in y_test] # don't want [Start], [End]\n",
        "    acc = []\n",
        "    for i in range(len(y_test)):\n",
        "        acc.append(token_accuracy(y_test_split[i], y_pred_split[i]))\n",
        "    return np.mean(acc)"
      ],
      "metadata": {
        "id": "oKimKGjDpt3G"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(y_test_text, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tFygD8Kq277",
        "outputId": "ee7f9d77-bd02-45c6-d012-d712b2cf1c64"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.006388194360143593"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "name": "2022-07-20-RNNAttention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('symba')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f5d976e6d509e4e27f2efe6a9897c82aaf49c602a756d97e47468f8a9400283d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}