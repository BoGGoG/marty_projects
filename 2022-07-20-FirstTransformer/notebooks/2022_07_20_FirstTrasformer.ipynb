{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j77hUjNXm5ib"
      },
      "source": [
        "https://keras.io/examples/nlp/neural_machine_translation_with_transformer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qEH2hbKAK5D",
        "outputId": "58f98cb1-161d-4a0a-96a1-c0e53c196f1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: icecream in /home/boggog/.local/lib/python3.10/site-packages (2.1.2)\n",
            "Requirement already satisfied: more_itertools in /home/boggog/.local/lib/python3.10/site-packages (8.13.0)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /home/boggog/.local/lib/python3.10/site-packages (from icecream) (0.4.4)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /home/boggog/.local/lib/python3.10/site-packages (from icecream) (2.12.0)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /home/boggog/.local/lib/python3.10/site-packages (from icecream) (2.0.5)\n",
            "Requirement already satisfied: executing>=0.3.1 in /home/boggog/.local/lib/python3.10/site-packages (from icecream) (0.8.3)\n",
            "Requirement already satisfied: six in /usr/lib/python3.10/site-packages (from asttokens>=2.0.1->icecream) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install icecream more_itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuKVH3YBBd6C",
        "outputId": "fdc451e1-0050-4d82-a82c-fc05c2ae40df"
      },
      "outputs": [],
      "source": [
        "# only needed for colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xzulqDrkBhLc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# os.chdir('/content/drive/MyDrive/SYMBA/2022-07-20-RNNAttention')\n",
        "os.chdir(\"..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5c0dUUGBr5W",
        "outputId": "a78f6b74-5f32-4fed-d3a6-a144e00342d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['source', 'notebooks', 'dev', 'README.md', 'test']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9A9Y1io1AKa6"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from icecream import ic \n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from source.read_amplitudes import read_amplitudes, fix_operator_num_args, get_tree, fix_tree, fix_subscript, fix_subscripts, read_amplitudes_and_squares\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EDUHCTk_AKa8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-20 14:14:10.615621: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2022-07-20 14:14:10.618316: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local//lib:\n",
            "2022-07-20 14:14:10.618329: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-WbL192AKa8"
      },
      "source": [
        "# Reading in Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhJwRNokAKa9",
        "outputId": "c3b7a3be-82a8-4f76-bc50-c8970b792f45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['source', 'notebooks', 'dev', 'README.md', 'test']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GGzjopcfAKa9"
      },
      "outputs": [],
      "source": [
        "amplitudes_file = \"../data.nosync/QED_amplitudes_TreeLevel_UpTo3to3.txt\"\n",
        "sqamplitudes_file = \"../data.nosync/QED_sqamplitudes_TreeLevel_UpTo3to3.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g8BWBW6FAKa-"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "with open(amplitudes_file, 'r') as f:\n",
        "    for line in f.readlines() :\n",
        "        line = line.split(\";\")\n",
        "        # have to remove new line character for some reason\n",
        "        line[-1] = line[-1].replace(\"\\n\", \"\")\n",
        "        # line = tf.strings.join(['[START]', line, '[END]'], separator=' ')\n",
        "        # X.append(['[START]'] + line + ['[END]'])\n",
        "        X.append(line)\n",
        "\n",
        "y = []\n",
        "with open(sqamplitudes_file, 'r') as f:\n",
        "    for line in f.readlines() :\n",
        "        line = line.split(\";\")\n",
        "        # have to remove new line character for some reason\n",
        "        line[-1] = line[-1].replace(\"\\n\", \"\")\n",
        "        # y.append(['[START]'] + line + ['[END]'])\n",
        "        y.append(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ONnK6W_ZAKa-"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_test, y_test, test_size=0.5, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGlFIj0OAKa_",
        "outputId": "f7328c33-b7f7-4e32-a59f-038d8944df43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Prod', '1/162', 'Prod', 'i', 'Prod', 'Pow', 'e', '4', 'Prod',\n",
              "       'Pow', 'Sum', 'Pow', 'm_s', '2', 'Sum', 's_23', 'Prod', '1/2',\n",
              "       'reg_prop', '-1', 'Prod', 'Pow', 'Sum', 'Pow', 'm_s', '2', 'Sum',\n",
              "       's_12', 's_13', 'Prod', '-1', 's_15', 's_23', 'Prod', '-1', 's_25',\n",
              "       'Prod', '-1', 's_35', 'Prod', '1/2', 'reg_prop', '-1', 'Prod',\n",
              "       'Pow', 'Sum', 's_15', 'Prod', '-1/2', 'reg_prop', '-1', 'Sum',\n",
              "       'Prod', 'p_1', 'alpha_33', 'Prod', 'p_1', 'alpha_12', 'Prod',\n",
              "       'gamma', 'alpha_33', 'alpha_47', 'alpha_11', 'Prod', 'gamma',\n",
              "       'alpha_28', 'alpha_4', 'alpha_41', 'Prod', 'A^(*)', 'i_5',\n",
              "       'alpha_12', '(p_5)', 'Prod', 'A^(*)', 'i_1', 'alpha_28', '(p_6)',\n",
              "       'Prod', 'd^(*)', 'i_2', 'alpha_4', '(p_1)_v', 'Prod', 'd', 'i_3',\n",
              "       'alpha_41', '(p_4)_v', 'Prod', 's', 'i_4', 'alpha_11', '(p_2)_u',\n",
              "       's^(*)', 'i_0', 'alpha_47', '(p_3)_v', 'Sum', 'Prod', '1/2',\n",
              "       'Prod', 'p_1', 'alpha_12', 'Prod', 'p_2', 'alpha_2', 'Prod',\n",
              "       'gamma', 'alpha_33', 'alpha_48', 'alpha_6', 'Prod', 'gamma',\n",
              "       'alpha_33', 'alpha_52', 'alpha_10', 'Prod', 'gamma', 'alpha_28',\n",
              "       'alpha_9', 'alpha_25', 'Prod', 'gamma', 'alpha_2', 'alpha_6',\n",
              "       'alpha_9', 'Prod', 'A^(*)', 'i_5', 'alpha_12', '(p_5)', 'Prod',\n",
              "       'A^(*)', 'i_1', 'alpha_28', '(p_6)', 'Prod', 'd^(*)', 'i_2',\n",
              "       'alpha_48', '(p_1)_v', 'Prod', 'd', 'i_3', 'alpha_25', '(p_4)_v',\n",
              "       'Prod', 's', 'i_4', 'alpha_10', '(p_2)_u', 's^(*)', 'i_0',\n",
              "       'alpha_52', '(p_3)_v', 'Prod', '1/2', 'Prod', 'p_1', 'alpha_12',\n",
              "       'Prod', 'p_3', 'alpha_2', 'Prod', 'gamma', 'alpha_33', 'alpha_49',\n",
              "       'alpha_44', 'Prod', 'gamma', 'alpha_33', 'alpha_30', 'alpha_50',\n",
              "       'Prod', 'gamma', 'alpha_28', 'alpha_38', 'alpha_37', 'Prod',\n",
              "       'gamma', 'alpha_2', 'alpha_44', 'alpha_38', 'Prod', 'A^(*)', 'i_5',\n",
              "       'alpha_12', '(p_5)', 'Prod', 'A^(*)', 'i_1', 'alpha_28', '(p_6)',\n",
              "       'Prod', 'd^(*)', 'i_2', 'alpha_49', '(p_1)_v', 'Prod', 'd', 'i_3',\n",
              "       'alpha_37', '(p_4)_v', 'Prod', 's', 'i_4', 'alpha_50', '(p_2)_u',\n",
              "       's^(*)', 'i_0', 'alpha_30', '(p_3)_v', 'Prod', '-1/2', 'Prod',\n",
              "       'p_1', 'alpha_33', 'Prod', 'p_5', 'alpha_34', 'Prod', 'gamma',\n",
              "       'alpha_33', 'alpha_14', 'alpha_51', 'Prod', 'gamma', 'alpha_34',\n",
              "       'alpha_32', 'alpha_63', 'Prod', 'gamma', 'alpha_12', 'alpha_26',\n",
              "       'alpha_32', 'Prod', 'gamma', 'alpha_28', 'alpha_63', 'alpha_53',\n",
              "       'Prod', 'A^(*)', 'i_5', 'alpha_12', '(p_5)', 'Prod', 'A^(*)',\n",
              "       'i_1', 'alpha_28', '(p_6)', 'Prod', 'd^(*)', 'i_2', 'alpha_26',\n",
              "       '(p_1)_v', 'Prod', 'd', 'i_3', 'alpha_53', '(p_4)_v', 'Prod', 's',\n",
              "       'i_4', 'alpha_51', '(p_2)_u', 's^(*)', 'i_0', 'alpha_14',\n",
              "       '(p_3)_v', 'Prod', '1/2', 'Prod', 's_15', 'Prod', 'gamma',\n",
              "       'alpha_33', 'alpha_0', 'alpha_40', 'Prod', 'gamma', 'alpha_33',\n",
              "       'alpha_15', 'alpha_42', 'Prod', 'gamma', 'alpha_12', 'alpha_57',\n",
              "       'alpha_0', 'Prod', 'gamma', 'alpha_28', 'alpha_40', 'alpha_8',\n",
              "       'Prod', 'A^(*)', 'i_5', 'alpha_12', '(p_5)', 'Prod', 'A^(*)',\n",
              "       'i_1', 'alpha_28', '(p_6)', 'Prod', 'd^(*)', 'i_2', 'alpha_57',\n",
              "       '(p_1)_v', 'Prod', 'd', 'i_3', 'alpha_8', '(p_4)_v', 'Prod', 's',\n",
              "       'i_4', 'alpha_42', '(p_2)_u', 's^(*)', 'i_0', 'alpha_15',\n",
              "       '(p_3)_v', 'Prod', '-1/2', 'Prod', 'p_1', 'alpha_12', 'Prod',\n",
              "       'p_5', 'alpha_34', 'Prod', 'gamma', 'alpha_33', 'alpha_62',\n",
              "       'alpha_60', 'Prod', 'gamma', 'alpha_33', 'alpha_35', 'alpha_17',\n",
              "       'Prod', 'gamma', 'alpha_34', 'alpha_59', 'alpha_62', 'Prod',\n",
              "       'gamma', 'alpha_28', 'alpha_60', 'alpha_58', 'Prod', 'A^(*)',\n",
              "       'i_5', 'alpha_12', '(p_5)', 'Prod', 'A^(*)', 'i_1', 'alpha_28',\n",
              "       '(p_6)', 'Prod', 'd^(*)', 'i_2', 'alpha_59', '(p_1)_v', 'Prod',\n",
              "       'd', 'i_3', 'alpha_58', '(p_4)_v', 'Prod', 's', 'i_4', 'alpha_17',\n",
              "       '(p_2)_u', 's^(*)', 'i_0', 'alpha_35', '(p_3)_v', 'Prod', '-1/4',\n",
              "       'Prod', 'p_2', 'alpha_2', 'Prod', 'p_5', 'alpha_34', 'Prod',\n",
              "       'gamma', 'alpha_33', 'alpha_54', 'alpha_31', 'Prod', 'gamma',\n",
              "       'alpha_33', 'alpha_46', 'alpha_61', 'Prod', 'gamma', 'alpha_34',\n",
              "       'alpha_5', 'alpha_54', 'Prod', 'gamma', 'alpha_12', 'alpha_68',\n",
              "       'alpha_5', 'Prod', 'gamma', 'alpha_28', 'alpha_18', 'alpha_24',\n",
              "       'Prod', 'gamma', 'alpha_2', 'alpha_31', 'alpha_18', 'Prod',\n",
              "       'A^(*)', 'i_5', 'alpha_12', '(p_5)', 'Prod', 'A^(*)', 'i_1',\n",
              "       'alpha_28', '(p_6)', 'Prod', 'd^(*)', 'i_2', 'alpha_68', '(p_1)_v',\n",
              "       'Prod', 'd', 'i_3', 'alpha_24', '(p_4)_v', 'Prod', 's', 'i_4',\n",
              "       'alpha_61', '(p_2)_u', 's^(*)', 'i_0', 'alpha_46', '(p_3)_v',\n",
              "       'Prod', '-1/4', 'Prod', 'p_3', 'alpha_2', 'Prod', 'p_5',\n",
              "       'alpha_34', 'Prod', 'gamma', 'alpha_33', 'alpha_55', 'alpha_13',\n",
              "       'Prod', 'gamma', 'alpha_33', 'alpha_21', 'alpha_45', 'Prod',\n",
              "       'gamma', 'alpha_34', 'alpha_23', 'alpha_55', 'Prod', 'gamma',\n",
              "       'alpha_12', 'alpha_36', 'alpha_23', 'Prod', 'gamma', 'alpha_28',\n",
              "       'alpha_3', 'alpha_19', 'Prod', 'gamma', 'alpha_2', 'alpha_13',\n",
              "       'alpha_3', 'Prod', 'A^(*)', 'i_5', 'alpha_12', '(p_5)', 'Prod',\n",
              "       'A^(*)', 'i_1', 'alpha_28', '(p_6)', 'Prod', 'd^(*)', 'i_2',\n",
              "       'alpha_36', '(p_1)_v', 'Prod', 'd', 'i_3', 'alpha_19', '(p_4)_v',\n",
              "       'Prod', 's', 'i_4', 'alpha_45', '(p_2)_u', 's^(*)', 'i_0',\n",
              "       'alpha_21', '(p_3)_v', 'Prod', '-1/2', 'Prod', 'p_1', 'alpha_12',\n",
              "       'Prod', 'p_5', 'alpha_2', 'Prod', 'gamma', 'alpha_33', 'alpha_65',\n",
              "       'alpha_56', 'Prod', 'gamma', 'alpha_33', 'alpha_1', 'alpha_39',\n",
              "       'Prod', 'gamma', 'alpha_28', 'alpha_20', 'alpha_66', 'Prod',\n",
              "       'gamma', 'alpha_2', 'alpha_56', 'alpha_20', 'Prod', 'A^(*)', 'i_5',\n",
              "       'alpha_12', '(p_5)', 'Prod', 'A^(*)', 'i_1', 'alpha_28', '(p_6)',\n",
              "       'Prod', 'd^(*)', 'i_2', 'alpha_65', '(p_1)_v', 'Prod', 'd', 'i_3',\n",
              "       'alpha_66', '(p_4)_v', 'Prod', 's', 'i_4', 'alpha_39', '(p_2)_u',\n",
              "       's^(*)', 'i_0', 'alpha_1', '(p_3)_v', 'Prod', '1/4', 'Prod', 'p_5',\n",
              "       'alpha_34', 'Prod', 'p_5', 'alpha_2', 'Prod', 'gamma', 'alpha_33',\n",
              "       'alpha_29', 'alpha_27', 'Prod', 'gamma', 'alpha_33', 'alpha_43',\n",
              "       'alpha_22', 'Prod', 'gamma', 'alpha_34', 'alpha_7', 'alpha_29',\n",
              "       'Prod', 'gamma', 'alpha_12', 'alpha_64', 'alpha_7', 'Prod',\n",
              "       'gamma', 'alpha_28', 'alpha_67', 'alpha_16', 'Prod', 'gamma',\n",
              "       'alpha_2', 'alpha_27', 'alpha_67', 'Prod', 'A^(*)', 'i_5',\n",
              "       'alpha_12', '(p_5)', 'Prod', 'A^(*)', 'i_1', 'alpha_28', '(p_6)',\n",
              "       'Prod', 'd^(*)', 'i_2', 'alpha_64', '(p_1)_v', 'Prod', 'd', 'i_3',\n",
              "       'alpha_16', '(p_4)_v', 'Prod', 's', 'i_4', 'alpha_22', '(p_2)_u',\n",
              "       's^(*)', 'i_0', 'alpha_43', '(p_3)_v'], dtype='<U8')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ACcZpcWYAKa_",
        "outputId": "21553f3b-7eec-4da6-d729-884bb0ec5555"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f96dcdc1ff0>]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot([len(x) for x in X_train])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_size = 400\n",
        "sequence_length = 250\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RpEx9LqAKa_",
        "outputId": "30833308-6add-4661-9c8d-0d69835638a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| len(X_train_idx_okay): 19266\n",
            "ic| len(X_test_idx_okay): 2438\n"
          ]
        }
      ],
      "source": [
        "X_train_idx_okay = np.where([len(x) < sequence_length for x in X_train])[0]\n",
        "X_val_idx_okay = np.where([len(x) < sequence_length for x in X_val])[0]\n",
        "X_test_idx_okay = np.where([len(x) < sequence_length for x in X_test])[0]\n",
        "ic(len(X_train_idx_okay));\n",
        "ic(len(X_test_idx_okay));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cUOZJ8QSAKbA"
      },
      "outputs": [],
      "source": [
        "X_train_short = [X_train[i] for i in X_train_idx_okay]\n",
        "y_train_short = [y_train[i] for i in X_train_idx_okay]\n",
        "\n",
        "X_val_short = [X_val[i] for i in X_val_idx_okay]\n",
        "y_val_short = [y_val[i] for i in X_val_idx_okay]\n",
        "\n",
        "X_test_short = [X_test[i] for i in X_test_idx_okay]\n",
        "y_test_short = [y_test[i] for i in X_test_idx_okay]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "K5ZGOW8MpcDA"
      },
      "outputs": [],
      "source": [
        "X_train_text = [\" \".join(x) for x in X_train_short]\n",
        "y_train_text = [\" \".join(yy) for yy in y_train_short]\n",
        "\n",
        "X_test_text = [\" \".join(x) for x in X_test_short]\n",
        "y_test_text = [\" \".join(yy) for yy in y_test_short]\n",
        "\n",
        "X_val_text = [\" \".join(x) for x in X_val_short]\n",
        "y_val_text = [\" \".join(yy) for yy in y_val_short]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def custom_standardization(input_string):\n",
        "    return input_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-20 14:14:17.562743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-07-20 14:14:17.562909: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local//lib:\n",
            "2022-07-20 14:14:17.563125: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local//lib:\n",
            "2022-07-20 14:14:17.563299: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local//lib:\n",
            "2022-07-20 14:14:17.563335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local//lib:\n",
            "2022-07-20 14:14:17.563369: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local//lib:\n",
            "2022-07-20 14:14:17.563523: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local//lib:\n",
            "2022-07-20 14:14:17.563560: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local//lib:\n",
            "2022-07-20 14:14:17.563717: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local//lib:\n",
            "2022-07-20 14:14:17.563722: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2022-07-20 14:14:17.564286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "X_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        "    standardize=None,\n",
        ")\n",
        "\n",
        "y_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length+1,\n",
        "    standardize=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_vectorization.adapt(X_train_text)\n",
        "y_vectorization.adapt(y_train_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(250,), dtype=int64, numpy=\n",
              "array([  2, 144,   2,  51,   2,   6, 107,  74,   2,   6,  52,  74,   2,\n",
              "         6,   4,   6,  92,   7,   4,   2,   8,  53,   2,  76,  49,   2,\n",
              "        76,  80,   2,  76,  75,   2,  76,  77,   2,   8,  79,   2, 104,\n",
              "        14,   5,   2,   6,   4,   6,  92,   7,   4,  53,   2,   8,  14,\n",
              "         5,   2,   6,   4,   6,  92,   7,   4,  53,   2,   5,  49,   2,\n",
              "         5,  75,   2,   8,  14,   5,   4,   2,  84,  35,   2,   3,  27,\n",
              "        34,  28,   2,   3,  27,  19,  41,   2,   3,  32,  29,  26,   2,\n",
              "         3,  32,  21,  37,   2,   3,  35,  41,  21,   2,  67,  11,  28,\n",
              "        38,   2,  66,  12,  34,  45,   2,  66,   9,  19,  42,   2,  67,\n",
              "        15,  37,  47,   2,  69,  10,  26,  54,  68,  13,  29,  78,   4,\n",
              "         2,  83,  35,   2,   3,  27,  40,  23,   2,   3,  27,  18,  22,\n",
              "         2,   3,  32,  20,  16,   2,   3,  32,  36,  30,   2,   3,  35,\n",
              "        22,  36,   2,  67,  11,  23,  38,   2,  66,  12,  40,  45,   2,\n",
              "        66,   9,  18,  42,   2,  67,  15,  30,  47,   2,  69,  10,  16,\n",
              "        54,  68,  13,  20,  78,   2,  93,   2,  82,  27,   2,   3,  27,\n",
              "        31,  25,   2,   3,  32,  24,  33,   2,   3,  32,  39,  17,   2,\n",
              "        67,  11,  25,  38,   2,  66,  12,  31,  45,   2,  66,   9,  39,\n",
              "        42,   2,  67,  15,  17,  47,   2,  69,  10,  33,  54,  68,  13,\n",
              "        24,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0])>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_vectorization(X_train_text[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_dataset(X, y):\n",
        "    X_vec = X_vectorization(X)\n",
        "    y_vec = y_vectorization(y)\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": X_vec,\n",
        "            \"decoder_inputs\": y_vec[:, :-1],\n",
        "        },\n",
        "        y_vec[:, 1:],\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(X_text, y_text):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X_text, y_text))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(X_train_text, y_train_text)\n",
        "val_ds = make_dataset(X_val_text, y_val_text)\n",
        "test_ds = make_dataset(X_test_text, y_test_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (16, 250)\n",
            "inputs[\"decoder_inputs\"].shape: (16, 250)\n",
            "targets.shape: (16, 250)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-20 14:14:21.315141: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'encoder_inputs': <tf.Tensor: shape=(16, 250), dtype=int64, numpy=\n",
            "array([[  2, 141,   2, ...,   0,   0,   0],\n",
            "       [  2, 127,   2, ...,   0,   0,   0],\n",
            "       [  2, 141,   2, ...,   0,   0,   0],\n",
            "       ...,\n",
            "       [  2, 114,   2, ...,   0,   0,   0],\n",
            "       [  2, 126,   2, ...,   0,   0,   0],\n",
            "       [  2, 133,   2, ...,   0,   0,   0]])>, 'decoder_inputs': <tf.Tensor: shape=(16, 250), dtype=int64, numpy=\n",
            "array([[  5,   2, 128, ...,   2,   6,  18],\n",
            "       [  5,   2,  69, ...,   3,   5,   3],\n",
            "       [  5,   2,  84, ...,   2,  13,  11],\n",
            "       ...,\n",
            "       [  5,   2,  78, ...,  48,   3,   5],\n",
            "       [  5,   2,  89, ...,   6,   2,   3],\n",
            "       [  5,   2,  92, ...,   2,  13,  17]])>}\n",
            "tf.Tensor(\n",
            "[[  2 128   2 ...   6  18   2]\n",
            " [  2  69   2 ...   5   3  22]\n",
            " [  2  84   2 ...  13  11   2]\n",
            " ...\n",
            " [  2  78   2 ...   3   5   3]\n",
            " [  2  89   2 ...   2   3   5]\n",
            " [  2  92   2 ...  13  17  48]], shape=(16, 250), dtype=int64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-07-20 14:15:16.034537: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(inputs)\n",
        "    print(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 512\n",
        "num_heads = 6\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding (Position  (None, None, 256)   166400      ['encoder_inputs[0][0]']         \n",
            " alEmbedding)                                                                                     \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 256)   1841664     ['positional_embedding[0][0]']   \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, None, 400)    3689104     ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,697,168\n",
            "Trainable params: 5,697,168\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "  33/1205 [..............................] - ETA: 8:27 - loss: 3.6498 - accuracy: 0.2706"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/boggog/Documents/marty_projects/2022-07-20-FirstTransformer/notebooks/2022_07_20_FirstTrasformer.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boggog/Documents/marty_projects/2022-07-20-FirstTransformer/notebooks/2022_07_20_FirstTrasformer.ipynb#ch0000029?line=2'>3</a>\u001b[0m transformer\u001b[39m.\u001b[39msummary()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boggog/Documents/marty_projects/2022-07-20-FirstTransformer/notebooks/2022_07_20_FirstTrasformer.ipynb#ch0000029?line=3'>4</a>\u001b[0m transformer\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boggog/Documents/marty_projects/2022-07-20-FirstTransformer/notebooks/2022_07_20_FirstTrasformer.ipynb#ch0000029?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrmsprop\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boggog/Documents/marty_projects/2022-07-20-FirstTransformer/notebooks/2022_07_20_FirstTrasformer.ipynb#ch0000029?line=5'>6</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/boggog/Documents/marty_projects/2022-07-20-FirstTransformer/notebooks/2022_07_20_FirstTrasformer.ipynb#ch0000029?line=6'>7</a>\u001b[0m transformer\u001b[39m.\u001b[39;49mfit(train_ds, epochs\u001b[39m=\u001b[39;49mepochs, validation_data\u001b[39m=\u001b[39;49mval_ds)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 1  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_vocab = y_vectorization.get_vocabulary()\n",
        "y_index_lookup = dict(zip(range(len(y_vocab)), y_vocab))\n",
        "max_decoded_sentence_length = 250\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = X_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = y_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = y_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[start] 227 prod i prod pow e 4 prod pow sum pow mu 2 sum s45 prod 12 regprop 1 prod pow sum pow mu 2 sum prod 1 s24 prod 1 s25 s45 prod 12 regprop 1 prod pow sum pow mc 2 sum pow mu 2 s23 prod 1 s14 prod 1 s15 prod 1 s24 prod 1 s25 s45 prod 12 regprop 1 sum prod p2 alpha11 prod gamma alpha11 alpha19 alpha11 prod gamma alpha11 alpha19 alpha11 prod gamma alpha11 alpha19 alpha11 prod c i1 alpha3 p1u prod c i3 alpha11 p6v prod t i0 alpha11 p1u prod t i5 alpha3 p2v prod u i4 alpha11 p4u u i2 alpha6 p5v sum prod 12 prod p4 alpha11 prod gamma alpha11 alpha1 alpha21 prod gamma alpha11 alpha1 alpha11 prod gamma alpha11 alpha11 alpha19 prod gamma alpha11 alpha11 alpha19 prod gamma alpha11 alpha24 alpha17 prod c i1 alpha11 p3v prod c i3 alpha3 p6v prod t i0 alpha11 p1u prod t i5 alpha11 p2v prod u i4 alpha11 p4u prod t i5 alpha11 p5v prod prod p5 alpha11 prod gamma alpha11 alpha22 alpha21 prod gamma alpha7 alpha19 alpha22 prod gamma alpha11 alpha24 alpha21 prod gamma alpha11 alpha21 alpha24 prod gamma alpha11 alpha24 alpha21 prod c i1 alpha11 p3v prod c i3 alpha11 p6v prod t i0 alpha11 p1u prod t i5 alpha3 p2v prod u i4 alpha11 p4u prod u i2 alpha11 p5v prod 12 regprop 1 prod gamma alpha11 p4u prod u i4 alpha11 p3v prod u i4 alpha11'"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decode_sequence(X_val_text[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(250,), dtype=int64, numpy=\n",
              "array([  2, 106,   2,  60,   2,   6,  61,  65,   2,   6,   4,   6,  30,\n",
              "         8,   4,  69,   2,   7,  14,   5,   2,   6,   4,   6,  30,   8,\n",
              "         4,   2,   5,  66,   2,   5,  67,  69,   2,   7,  14,   5,   2,\n",
              "         6,   4,   6,  82,   8,   4,   6,  30,   8,  62,   2,   5,  58,\n",
              "         2,   5,  72,   2,   5,  66,   2,   5,  67,  69,   2,   7,  14,\n",
              "         5,   4,   2,  71,  33,   2,   3,  16,  20,  42,   2,   3,  16,\n",
              "        29,  28,   2,   3,  33,  19,  41,   2,  47,  10,  29,  51,   2,\n",
              "        47,  12,  28,  53,   2,  45,  11,  42,  39,   2,  45,  15,  20,\n",
              "        54,   2,  48,  13,  19,  43,  48,   9,  41,  56,   4,   2,   7,\n",
              "         2,  74,  17,   2,   3,  17,  23,  31,   2,   3,  16,  31,  37,\n",
              "         2,   3,  16,  40,  24,   2,   3,  33,  32,  23,   2,   3,  33,\n",
              "        22,  18,   2,  47,  10,  40,  51,   2,  47,  12,  24,  53,   2,\n",
              "        45,  11,  37,  39,   2,  45,  15,  32,  54,   2,  48,  13,  22,\n",
              "        43,  48,   9,  18,  56,   2,   7,   2,  70,  17,   2,   3,  17,\n",
              "        36,  27,   2,   3,  16,  27,  21,   2,   3,  16,  38,  35,   2,\n",
              "         3,  33,  25,  36,   2,   3,  33,  34,  26,   2,  47,  10,  38,\n",
              "        51,   2,  47,  12,  35,  53,   2,  45,  11,  21,  39,   2,  45,\n",
              "        15,  25,  54,   2,  48,  13,  34,  43,  48,   9,  26,  56,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0])>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_vectorization(X_val_text[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "2022-07-20-RNNAttention.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "symba",
      "language": "python",
      "name": "symba"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "f5d976e6d509e4e27f2efe6a9897c82aaf49c602a756d97e47468f8a9400283d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
